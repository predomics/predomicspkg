\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8]{inputenc} % @SET ENCODING@
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `predomics'}}
\par\bigskip{\large \today}
\end{center}
\inputencoding{utf8}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {predomics: Interpretable Prediction in large Omics Dataests}}}{}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Interpretable Prediction in large Omics Dataests}
\item[Version]\AsIs{1.2.0}
\item[Date]\AsIs{2023-10-31}
\item[Author]\AsIs{Edi Prifti, 
Eugeni Belda,
Lucas Robin, 
Shasha Cui, 
Blaise Hanczar, 
Yann Chevaleyre, 
Jean-Daniel Zucker}
\item[Maintainer]\AsIs{Edi Prifti }\email{edi.prifti@ird.fr}\AsIs{}
\item[Depends]\AsIs{R (>= 2.15.0),}
\item[Imports]\AsIs{ggplot2, reshape2, logger, data.table, BioQC, foreach, snow,
doRNG, doSNOW, yaml, cowplot, patchwork, gridExtra, grid,
gtools, RColorBrewer, viridis, pROC, caTools, glmnet, kernlab,
randomForest, effsize}
\item[Suggests]\AsIs{knitr, rmarkdown, testthat}
\item[VignetteBuilder]\AsIs{knitr}
\item[Description]\AsIs{The predomics package offers access to a novel framework implementing several heuristics that allow finding
sparse and interpretable models in large datasets. These models are efficient and adopted for classification and regression 
in metagenomics and other commensurable datasets. We introduce the BTR (BIN, TER, RATIO) languages that describe different 
types of associations between variables. Moreover, in the same framework we implemented several state-of-the-art methods 
(SOTA) including RF, ENET and SVM.}
\item[License]\AsIs{GPL-3}
\item[LazyData]\AsIs{TRUE}
\item[RoxygenNote]\AsIs{7.2.3}
\item[Encoding]\AsIs{UTF-8}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{AnalyseStableModels\_LOO}{analyse stability of models from digest}{AnalyseStableModels.Rul.LOO}
%
\begin{Description}
This function analyses prevalence of features of best model of different sparsity in crossval (here still k-folds)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
AnalyseStableModels_LOO(X, y, clf, tmp, loo)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{tmp:}] the digested result object from digest
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of each sparsity the frequency of each feature of empirical best model in k-folds cross validation
\end{Value}
\inputencoding{utf8}
\HeaderA{analyzeImportanceFeatures}{Prints as text the detail on a given experiment along with summarized results (if computed)}{analyzeImportanceFeatures}
%
\begin{Description}
This function takes a population of models and makes three plots, feature prevalence in population, 
feature abundance by class and feature prevalence by class
\end{Description}
%
\begin{Usage}
\begin{verbatim}
analyzeImportanceFeatures(
  clf_res,
  X,
  y,
  makeplot = TRUE,
  name = "",
  verbose = TRUE,
  pdf.dims = c(width = 25, height = 20),
  filter.perc = 0.05,
  filter.cv.prev = 0.25,
  nb.top.features = 100,
  scaled.importance = FALSE,
  k_penalty = 0.75/100,
  k_max = 0
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf\_res:}] the result of an experiment or multiple exmeriments (list of experimenets)

\item[\code{X:}] the X dataset where to compute the abundance and prevalence

\item[\code{y:}] the target class

\item[\code{makeplot:}] make a pdf file with the resulting plots (default:TRUE)

\item[\code{name:}] the suffix of the pdf file (default:"")

\item[\code{verbose:}] print out informaiton

\item[\code{pdf.dims:}] dimensions of the pdf object (default: c(w = 25, h = 20))

\item[\code{filter.perc:}] filter by prevalence percentage in the population between 0 and 1 (default:0.05)

\item[\code{filter.cv.prev:}] keep only features found in at least (default: 0.25, i.e 25 percent) of the cross validation experiments

\item[\code{nb.top.features:}] the maximum number (default: 100) of most important features to be shown. If this value is NULL 
or NA, all features be returned

\item[\code{scaled.importance:}] the scaled importance is the importance multipied by the prevalence in the folds. If (default = TRUE) this will be used, the mean mda 
will be scaled by the prevalence of the feature in the folds and ordered subsequently

\item[\code{k\_penalty:}] the sparsity penalty needed to select the best models of the population (default:0.75/100).

\item[\code{k\_max:}] select the best population below a given threshold. If (default:0) no selection is performed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
plots if makeplot is FALSE
\end{Value}
\inputencoding{utf8}
\HeaderA{analyzeImportanceFeaturesFBM}{Visualize a summary of an experiment/set of experiments}{analyzeImportanceFeaturesFBM}
%
\begin{Description}
Visualization of 4 panels corresponding to feature prevalence in FBM, feature importance, feature prevalence in groups, effect sizes of feature abundances vs y-variable (cliff's delta for binary y; spearman rho for continuous y)
Can be applied to single classification task or to multiple classification tasks carried out on the same X-y dataset
\end{Description}
%
\begin{Usage}
\begin{verbatim}
analyzeImportanceFeaturesFBM(
  clf_res,
  X,
  y,
  makeplot = TRUE,
  saveplotobj = TRUE,
  name = "",
  verbose = TRUE,
  pdf.dims = c(width = 25, height = 20),
  filter.cv.prev = 0.25,
  nb.top.features = 100,
  scaled.importance = FALSE,
  k_penalty = 0.75/100,
  k_max = 0
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf\_res}] The result of an experiment or multiple experiments (list of experiments)

\item[\code{X}] The feature table used as input of fit function behind experiments in clf\_res

\item[\code{y}] The target class (binary/continuous)

\item[\code{makeplot}] make a pdf file with the resulting plots (default:TRUE)

\item[\code{saveplotobj}] make a .Rda file with a list of the individual plots (default:TRUE)

\item[\code{name}] the suffix of the pdf file (default:"")

\item[\code{verbose}] print out informaiton

\item[\code{pdf.dims}] dimensions of the pdf object (default: c(w = 25, h = 20))

\item[\code{filter.cv.prev}] keep only features found in at least (default: 0.25, i.e 25 percent) of the cross validation experiments

\item[\code{nb.top.features}] the maximum number (default: 100) of most important features to be shown.
If the number of features in FBM < nb.top.features, the number of features in FBM will be shown instead

\item[\code{scaled.importance}] the scaled importance is the importance multipied by the prevalence in the folds. If (default = TRUE) this will be used, the mean mda 
will be scaled by the prevalence of the feature in the folds and ordered subsequently

\item[\code{k\_penalty}] the sparsity penalty needed to select the best models of the population (default:0.75/100).

\item[\code{k\_max}] select the best population below a given threshold. If (default:0) no selection is performed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
plots if makeplot is FALSE; plot.list list object saved locally with individual plots (including source data) if saveplotobj
\end{Value}
\inputencoding{utf8}
\HeaderA{analyzePopulationFeatures}{Prints as text the detail on a given experiment along with summarized results (if computed)}{analyzePopulationFeatures}
%
\begin{Description}
This function takes a population of models and makes three plots, feature prevalence in population, 
feature abundance by class and feature prevalence by class
\end{Description}
%
\begin{Usage}
\begin{verbatim}
analyzePopulationFeatures(
  pop,
  X,
  y,
  res_clf,
  makeplot = TRUE,
  name = "",
  ord.feat = "importance",
  make.network = TRUE,
  network.layout = "circular",
  network.alpha = 1e-04,
  verbose = TRUE,
  pdf.dims = c(width = 25, height = 20),
  filter.perc = 0.05,
  k_penalty = 0.75/100,
  k_max = 0
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population of models

\item[\code{X:}] the X dataset where to compute the abundance and prevalence

\item[\code{y:}] the target class

\item[\code{res\_clf:}] the results of the classifier as well as the config object

\item[\code{makeplot:}] make a pdf file with the resulting plots (default:TRUE)

\item[\code{name:}] the suffix of the pdf file (default:"")

\item[\code{ord.feat:}] which ordering approch to use for the features (default:importance) in the models, anything 
else will compute automatic hierarchical ordering based on the manhattan distance

\item[\code{make.network:}] build a network and print it out in the pdf

\item[\code{network.layout:}] the network layout by default is circular (layout\_in\_circle) and will be a weighted Fruchterman-Reingold otherwise

\item[\code{network.alpha:}] threshold of significance for the network (default:1e-4)

\item[\code{verbose:}] print out informaiton

\item[\code{pdf.dims:}] dimensions of the pdf object (default: c(w = 25, h = 20))

\item[\code{filter.perc:}] filter by prevalence percentage in the population between 0 and 1 (default:0.05)

\item[\code{k\_penalty:}] the sparsity penalty needed to select the best models of the population (default:0.75/100).

\item[\code{k\_max:}] select the best population below a given threshold. If (default:0) no selection is performed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
plots if makeplot is FALSE
\end{Value}
\inputencoding{utf8}
\HeaderA{bestModelFeatureStability}{analyse stability of models from digest}{bestModelFeatureStability}
%
\begin{Description}
This function analyses prevalence of features of best model of different sparsity in crossval (here still k-folds)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
bestModelFeatureStability(X, y, clf, digested.result, method = "fuzzy")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{digested.result:}] the digest result from digest

\item[\code{method:}] wether to compute the stability of the best compared to the best in the folds (exact), or the top best (fuzzy)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object with first a list of feature presence tables for each k\_sparsity and a list of feature presence frequency
\end{Value}
\inputencoding{utf8}
\HeaderA{bestModelStability}{analyse stability of models from digest}{bestModelStability}
%
\begin{Description}
This function analyses prevalence of features of best model of different sparsity in crossval (here still k-folds)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
bestModelStability(X, y, clf, digested.result, method = "exact")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{digested.result:}] the digest result from digest

\item[\code{method:}] wether to compute the stability of the best compared to the best in the folds (exact), or the top best (fuzzy)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object with first a list of feature presence tables for each k\_sparsity and a list of feature presence frequency
\end{Value}
\inputencoding{utf8}
\HeaderA{cir\_test}{Cirhosis stage 2 (frequencies)}{cir.Rul.test}
\keyword{cirrhosis,}{cir\_test}
\keyword{liver}{cir\_test}
\keyword{microbiome,}{cir\_test}
\keyword{species}{cir\_test}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/
This is a list containing two elements: (i) the X data matrix with 1045 species and 56 observations and (ii) patient class = -1 (n=25) and healthy controls (n=31)
\end{Description}
%
\begin{Author}
Qin, Nan, Fengling Yang, Ang Li, Edi Prifti, Yanfei Chen, Li Shao, Jing Guo, et al “Alterations of the human gut microbiome in liver cirrhosis.” Nature 513, no. 7516 (July 23, 2014): 59–64.
\end{Author}
\inputencoding{utf8}
\HeaderA{cir\_train}{Cirhosis stage 1 (frequencies)}{cir.Rul.train}
\keyword{cirrhosis,}{cir\_train}
\keyword{liver}{cir\_train}
\keyword{microbiome,}{cir\_train}
\keyword{species}{cir\_train}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/. 
This is a list containing two elements: (i) the X data matrix with 1045 species and 181 observations and (ii) patient class = -1 (n=98) and healthy controls (n=83)
\end{Description}
%
\begin{Author}
Qin, Nan, Fengling Yang, Ang Li, Edi Prifti, Yanfei Chen, Li Shao, Jing Guo, et al “Alterations of the human gut microbiome in liver cirrhosis.” Nature 513, no. 7516 (July 23, 2014): 59–64 \_.
\end{Author}
\inputencoding{utf8}
\HeaderA{cleanPopulation}{cleanPopulation}{cleanPopulation}
%
\begin{Description}
Looks for invalid predomics objects in a population and removes them.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
cleanPopulation(pop, clf)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] is population (a list) of predomics objects

\item[\code{clf:}] the classifier object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population of predomics objects
\end{Value}
\inputencoding{utf8}
\HeaderA{computeCardEnrichment}{computeCardEnrichment}{computeCardEnrichment}
%
\begin{Description}
Computes statistic for enrichment of the cardinality of a score for a two class vector
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeCardEnrichment(v.card.mat, y)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{v.card.mat:}] a dataframe with the cardinality of each feature (columns) and each group in the y vector (rows)

\item[\code{y:}] the vector containing the class specification for each sample
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a data.frame with the statistics computed
\end{Value}
\inputencoding{utf8}
\HeaderA{computeCoeffSVMLin}{Compute other prediction scores such as precision, recall and f-score}{computeCoeffSVMLin}
%
\begin{Description}
This function computes prediction scores based on the confusion matrix such as accuracy, precision, recall and f-score
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeCoeffSVMLin(X, y, clf = NULL, mod = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{mod:}] a predomics object to be updated

\item[\code{clf:}] an object containing the different parameters of the classifier
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model whose evaluation parameters are updated or a list containing coefficients and intercept if mod is not set.
\end{Value}
\inputencoding{utf8}
\HeaderA{computeConfusionMatrix}{Evaluates the confusion Matrix of the predicted class and the class to predict}{computeConfusionMatrix}
%
\begin{Description}
This function evaluates the accuracy of a model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeConfusionMatrix(mod, X, y, clf)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object to be evaluated

\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a confusion matrix
\end{Value}
\inputencoding{utf8}
\HeaderA{computeEffectSizes}{Compute effect sizes for features in binary classification/regression tasks}{computeEffectSizes}
%
\begin{Description}
In binary classification tasks, compute the cliff's delta effect sizes btw groups (1 vs. -1) + pvalues from wilcoxon rank-sum tests; in regression tasks, compute spearman correlations (rho + pvalue) vs. continuous y variable
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeEffectSizes(X, y, mode)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X}] The X matrix (rows=features; columns=samples)

\item[\code{y}] The y vector of sample class (-1,1 in binary classification; continuous variable in regression)

\item[\code{mode}] classification or regression
\end{ldescription}
\end{Arguments}
%
\begin{Value}
data frame of features, effect sizes (cliff's delta for binary classification; spearman rho for regression), and pvalues (wicoxon rank-sum test for binary classification task; spearman correlation for regression)
\end{Value}
\inputencoding{utf8}
\HeaderA{computeFeatureMetrics}{Computes different metrics for a given distributions}{computeFeatureMetrics}
%
\begin{Description}
This function computes to compute a certain number of metrics on a dataset for each variable 
(rows, such as prevalence, quartile distribution, etc.)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeFeatureMetrics(data)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data:}] a data frame containing the data to be treated.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a data frame containing different metrics: variance\_to\_mean, signal\_to\_noise, variation\_coefficient, efficiency and quartile\_dispertion
\end{Value}
\inputencoding{utf8}
\HeaderA{computeIntercept}{Computes the best intercept for the model while minimizing error}{computeIntercept}
%
\begin{Description}
Computes the best intercept for the model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
computeIntercept(score, y, verbose = FALSE, sign = "auto", plot = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{score:}] the \textasciicircum{}y score of the model

\item[\code{y:}] the response vector

\item[\code{verbose:}] print running information when set to TRUE

\item[\code{sign:}] weather the score should be greater or smaller than the intercept (default:"auto")

\item[\code{return.all:}] if TRUE, the function will return the intercept as well as the table used to compute it.

\item[\code{plot:}] if TRUE, the score will be visialized (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the intercept, the sign and the accuracy
\end{Value}
\inputencoding{utf8}
\HeaderA{counter}{The counter for the experiment id (used in the clf builders)}{counter}
%
\begin{Description}
The counter for the experiment id (used in the clf builders)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
counter()
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{crossing}{Creates new combinations of features based from a parents.}{crossing}
%
\begin{Description}
This function is used in terga1 will create new combinations of features based of existing ones from the parents.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
crossing(clf, pop, parents, seed = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier parameter object

\item[\code{pop:}] A population (i.e. list) of index vectors

\item[\code{parents:}] Indexes of the population pointing to the subset of the population containing the parents (whose genes/features) will be used to create the children.

\item[\code{seed:}] For reproductibility purpose to fix the random generator number.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population of models, containing parents and children
\end{Value}
\inputencoding{utf8}
\HeaderA{denseVecToModel}{denseVecToModel}{denseVecToModel}
%
\begin{Description}
Builds a model object based on model that is in the dense (long) format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
denseVecToModel(X, y, v, clf, eval.all = FALSE, obj = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{v:}] A vector of coeffs (example v=c(0.0,1.0,0.0,-1.0))

\item[\code{clf:}] classifier information

\item[\code{eval.all:}] If TRUE the fitting of the function and intercept will be computed

\item[\code{obj:}] an object model to add to the model (default:NULL)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an model object
\end{Value}
\inputencoding{utf8}
\HeaderA{digest}{Summarize the results from an experiment object}{digest}
%
\begin{Description}
Sumarizes the results of an experiment object of the type 
`obj\$classifier` and `obj\$crossval`. This is different from the digestMC(),
which sumarizes a model collection obj\$models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
digest(
  obj,
  penalty = NULL,
  best.cv = TRUE,
  best.k = NULL,
  plot = FALSE,
  omit.na = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] The experiment object resulting from the learning process `fit()`

\item[\code{penalty:}] A coefficient between 0 and 1, which is applied to penalize 
the performance of models as a consequence of model-size. We use this to select
the best model of the population of models (default:NULL)

\item[\code{best.cv:}] Should we chose the best model based on information learnerd 
cross validation (default:TRUE). This will work if the crossvalidation data is 
available. If not the best model will be selected with empirical results.

\item[\code{best.k:}] If we do not wish to let the algorithm select the model size, 
we can fix this by setting the best.k with an integer indicating the number of 
variables in the model (default:NULL).

\item[\code{plot:}] Should the digested results be plotted ? (default:FALSE)

\item[\code{omit.na:}] Omit data with empty results (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object with digested information such as the best models for each 
model-size, their respective scores, the best model.
\end{Value}
\inputencoding{utf8}
\HeaderA{digestModelCollection}{digestModelCollection}{digestModelCollection}
%
\begin{Description}
Sumarizes the results of a model collection object of the type clf\_res\$models. This is different from the digest() which sumarizes an experiment clf\_res\$classifier\$models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
digestModelCollection(obj, X = NULL, clf, k.penalty = 0, mmprev = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a modelCollection object

\item[\code{X:}] the dataset (default = NULL)

\item[\code{clf:}] the classifier object

\item[\code{k.penalty:}] the penalty to apply for sparsity (default:0).

\item[\code{mmprev:}] activate the max.min.prevalence selector (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Summarize the results from a given modelCollection object
\end{Details}
%
\begin{Value}
an object with sumarized results such as the best models for each k\_sparse, their respective scores, the best model, etc
\end{Value}
\inputencoding{utf8}
\HeaderA{disectModel}{Analyzes the score construction and model}{disectModel}
%
\begin{Description}
Analyzes the score construction and model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
disectModel(mod, X, y, clf, plot = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object where the score will be computed

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{plot:}] plot graphical interpretation of if TRUE, (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object containing statistics on a given model
\end{Value}
\inputencoding{utf8}
\HeaderA{estimateFeatureImportance}{Estimates the importance of each feature in the model object}{estimateFeatureImportance}
%
\begin{Description}
Estimates the importance of each feature in the model object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
estimateFeatureImportance(
  mod,
  X,
  y,
  clf,
  attribute = "unpenalized_fit_",
  plot.importance = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{attribute:}] which attribute should be used to compute the importance (default:unpenalized\_fit\_)

\item[\code{plot.importance:}] should the function plot the improtance of the features (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model object with the importance of each feature computed. Negative importance of a feature means that the feature is not beneficial.
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateAccuracy}{Evaluates the accuracy of a model}{evaluateAccuracy}
%
\begin{Description}
This function evaluates the accuracy of either (1) a model object that contains intercept and sign or (2) directly the attributes score, intercept, sign
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateAccuracy(
  mod = NULL,
  X,
  y,
  clf,
  force.re.evaluation = FALSE,
  mode = "train"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object to be used in the class prediction

\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{force.re.evaluation:}] evaluate again all the elements needed for accuracy (default:FALSE)

\item[\code{mode:}] training or test mode. If training, the funciton maximizes accuracy.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
either (1) a model whose evaluation parameters are updated or (2) the accuracy
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateAdditionnalMetrics}{Compute other prediction scores such as precision, recall and f-score}{evaluateAdditionnalMetrics}
%
\begin{Description}
This function computes prediction scores based on the confusion matrix such as accuracy, precision, recall and f-score
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateAdditionnalMetrics(mod, X, y, clf, mode = "train")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object to be evaluated

\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{mode:}] training or testing mode
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model whose evaluation parameters are updated
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateAUC}{Computes the AUC of a model}{evaluateAUC}
%
\begin{Description}
Computes the AUC of a model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateAUC(score, y, sign = ">")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{score:}] the \textasciicircum{}y score of the model

\item[\code{y:}] the response vector

\item[\code{sign:}] in which direction to make the comparison? "auto" (default): automatically define in which group 
the median is higher and take the direction accordingly. ">": if the predictor values for the control group 
are higher than the values of the case group (controls > t >= cases). "<": if the predictor values for the 
control group are lower or equal than the values of the case group (controls < t <= cases).
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an auc value
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateFeatureImportanceInPopulation}{evaluates the feature importance in a population of models}{evaluateFeatureImportanceInPopulation}
%
\begin{Description}
This function perturbes the dataset by shuffling one at a time a subset of features that appear in a population of models
and recomputes the evaluation of those models. The mean deltas of the score to consider will give a measure of importance. Two methods 
are implemented: the first (extensive), will shuffle feature by feature multiple times and will compute the evaluation for the whole 
population of models, which can be very time consuming. The second (optimized) and the default approach consists on using a different 
seed when shuffling a given feature and computing the population. In this setting it is not needed to run multiple seeds on the whole 
dataset. This procedure is designed to be applied in cross validation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateFeatureImportanceInPopulation(
  pop,
  X,
  y,
  clf,
  score = "fit_",
  filter.ci = TRUE,
  method = "optimized",
  seed = c(1:10),
  aggregation = "mean",
  verbose = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population of models to be considered. This population will be filtered if filter.ci = TRUE (default) using the interval 
confidence computed around the best model using a binomial distribution.

\item[\code{X:}] dataset used to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{score:}] the attribute of the model to be considered in the evaluation (default:fit\_)

\item[\code{filter.ci:}] filter the population based on the best model confidence interval (default:TRUE)

\item[\code{method:}] Two methods are implemented: the first (extensive), will shuffle feature by feature multiple times and will compute the 
evaluation for the whole population of models, which can be very time consuming. The second (optimized) and the default approach consists 
on using a different seed when shuffling a given feature and computing the population.

\item[\code{seed:}] one or more seeds to be used in the extensive method shuffling (default:c(1:10). For the optimized method only the first seed will be used 
and the rest of the seeds that are needed for each model will be incremented from there.

\item[\code{aggregation:}] the method to be used to aggregate the evaluation for a the whole population (default: mean), but can be either mean or median.

\item[\code{verbose:}] wether to print out information during the execution process.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a data.frame with features in rows and the population mean/median score for each model*seed of the population
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateFit}{Evaluates the fitting score of a model object}{evaluateFit}
%
\begin{Description}
Evaluates the fitting score of a model object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateFit(mod, X, y, clf, force.re.evaluation = FALSE, mode = "train")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod}] : a model object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{force.re.evaluation:}] re-evaluate all the scores even if they exist (default:FALSE)

\item[\code{mode:}] A choice from c("train", "test") indicates wether we wish to learn the threthold 
of the model (default:"train") or not "test" for the c("terinter","bininter","ratio") languages
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model object with the fitting score
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateIntercept}{Evaluates the fitting score of a model object}{evaluateIntercept}
%
\begin{Description}
Evaluates the fitting score of a model object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateIntercept(mod, X, y, clf)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod}] : a model object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model object with the fitting score
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateModel}{Evaluates the fitting score of a model object}{evaluateModel}
%
\begin{Description}
Evaluates the fitting score of a model object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateModel(
  mod,
  X,
  y,
  clf,
  eval.all = FALSE,
  force.re.evaluation = FALSE,
  estim.feat.importance = FALSE,
  mode = "train"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{eval.all:}] should the function evaluate all the scores (default:FALSE)

\item[\code{force.re.evaluation:}] re-evaluate all the scores even if they exist (default:FALSE)

\item[\code{estim.feat.importance:}] evaluate the importance in the model object (default:FALSE)

\item[\code{mode:}] A choice from c("train", "test") indicates wether we wish to learn the threthold 
of the model (default:"train") or not "test" for the c("terinter","bininter","ratio") languages
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model object with the fitting scores evaluated
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateModelRegression}{Evaluates the fitting coefficents of a model object}{evaluateModelRegression}
%
\begin{Description}
Evaluates the fitting coefficients of a model object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateModelRegression(
  mod,
  X,
  y,
  clf,
  eval.all = FALSE,
  force.re.evaluation = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{eval.all:}] should the function evaluate all the scores (default:FALSE)

\item[\code{force.re.evaluation:}] re-evaluate all the scores even if they exist (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model object with the fitting scores evaluated
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluatePopulation}{evaluatePopulation}{evaluatePopulation}
%
\begin{Description}
Evaluates an entire population of models, that be predomics objects or individuals
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluatePopulation(
  X,
  y,
  clf,
  pop,
  eval.all = FALSE,
  force.re.evaluation = FALSE,
  estim.feat.importance = FALSE,
  mode = "train",
  delete.null.models = TRUE,
  lfolds = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{clf:}] the object containing the classifier information

\item[\code{pop:}] the population of models to be evaluated

\item[\code{eval.all:}] should the function evaluate all the scores for each of the models (default:FALSE)

\item[\code{force.re.evaluation:}] re-evaluate all the scores even if they exist for each of the models (default:FALSE)

\item[\code{estim.feat.importance:}] evaluate the importance in the model object for each of the models (default:FALSE)

\item[\code{mode:}] A choice from c("train", "test") indicates wether we wish to learn the threthold 
of each of the models (default:"train") or not "test" for the c("terinter","bininter","ratio") languages

\item[\code{delete.null.models:}] should null indivuals be deleted (default:TRUE)

\item[\code{lfolds:}] compute evaluation in crossval (default:NULL)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an individual object
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluatePrevalence}{Evaluate the prevalence of a given model}{evaluatePrevalence}
%
\begin{Description}
Evaluate the prevalence of a given model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluatePrevalence(mod, X)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object

\item[\code{X:}] dataset where to compute the prevalence
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector containing the prevalence of each feature
\end{Value}
\inputencoding{utf8}
\HeaderA{evaluateYhat}{Computes the predected classification using a given model}{evaluateYhat}
%
\begin{Description}
This function evaluates the predicted classification either using (1) a model object that contains intercept and sign or (2) directly the attributes score, intercept, sign
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evaluateYhat(
  mod = NULL,
  X,
  y,
  clf,
  score = NULL,
  intercept = NULL,
  sign = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object to be used in the class prediction

\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{score:}] the score passed directly

\item[\code{intercept:}] the intercept passed directly

\item[\code{sign:}] the sign passed directly
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector with the predicted classification of the samples
\end{Value}
\inputencoding{utf8}
\HeaderA{evolve}{Creates new combinations of features based from a parents.}{evolve}
%
\begin{Description}
This function is used in terga1 and is the main engine of the algorithm that allows to cross, mutate and select individuals from one generation to the next.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evolve(X, y, clf, pop, seed = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{pop:}] A population (i.e. list) of index vectors

\item[\code{seed:}] For reproductibility purpose to fix the random generator number.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population of models, containing parents and children
\end{Value}
\inputencoding{utf8}
\HeaderA{evolve2m}{Second version of the evolve method}{evolve2m}
%
\begin{Description}
This evolve method realize the selection of the parents with 
two methods (for the moment) : elite and random. The it tags every selected 
individual with the index of it's mate in the population. Then the individual 
which sould be mutated are tagged. for each individual of the population we 
check if they need to be crossed and/or mutated and the we apply the operations 
and create a new individual for each operation applied.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evolve2m(X, y, clf, pop, featEval, generation)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] Dataset to classify

\item[\code{y:}] Variable to predict

\item[\code{clf:}] The claffifier  object containing the different parameters

\item[\code{pop:}] The population to be evolved

\item[\code{featEval:}] A dataframe with the evaluation of each variable of the dataset, 
used for some mutator.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with the size\_pop bests of the combination of the old population 
with the new population
\end{Value}
\inputencoding{utf8}
\HeaderA{evolve3m}{Another version of the evolve method that distingishes the different lanugages}{evolve3m}
%
\begin{Description}
In a nutshell this evolve method will select the parents using 2 methods (elite and random).
Then it tags every selected individual with the index of it's mate in the population. 
Then the individuals which are randomly selected and tagged as to be mutated. For each individual of the 
population we check if they need to be crossed and/or mutated and the we apply the operations and 
create a new individual for each operation applied. If two parents are of different languages the algorithm 
will produce two children that are the same with each having one of the languages.
This as been as a pipeline that could be paralellized with the most efficiency. We could summarize it the following way : 
IN -> Evaluation -> initialisation of the tags -> Tagging -> Crossing and mutation -> OUT (newpop)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
evolve3m(X, y, clf, pop, featEval)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{y:}] variable to predict

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{pop:}] the population to be evolved

\item[\code{featEval:}] a dataset with the evaluation of each variable of the dataset, used for some mutator.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with every new individuals
\end{Value}
\inputencoding{utf8}
\HeaderA{filterFeaturesByPrevalence}{Selects the most prevalent features in the dataset baset on the provided thresholds.}{filterFeaturesByPrevalence}
%
\begin{Description}
Filters out all features that display a prevalence below a given threshold provided as a number of 
observations or percentage. This for the total dataset or by class.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
filterFeaturesByPrevalence(
  X,
  y = NULL,
  nb.prevalence = NULL,
  perc.prevalence = NULL,
  by.class = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the dataset X

\item[\code{y:}] the class vector (default:NULL)

\item[\code{nb.prevalence:}] the minimum number of non zero observations (default: 10)

\item[\code{perc.prevalence:}] the percentage of non zero observations (default: NULL)

\item[\code{by.class:}] wether the filter should be applied by class (default: TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the filtered dataset, without the features that do not pass the filter.
\end{Value}
\inputencoding{utf8}
\HeaderA{filterfeaturesK}{Selects a the top k features that are significantly associated with the class to predict}{filterfeaturesK}
%
\begin{Description}
Runs statistics on the data and selects a subset of k features that are the most significant. 
An accelerated version is implemented based on the BioQC package for the Mann-Whittney tests. Besides filtering 
this function can be used in a more larger statistical context.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
filterfeaturesK(
  data,
  trait,
  k = 10,
  type = "wilcoxon",
  restrict = rep(TRUE, ncol(data)),
  multiple.adjust = "BH",
  paired = FALSE,
  sort = TRUE,
  verbose = FALSE,
  verbose.step = NULL,
  return.data = FALSE,
  accelerate = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data:}] the dataset X

\item[\code{trait:}] is the equivalent of y (class, or numerical)

\item[\code{k:}] the number of features (default:10)

\item[\code{type:}] the statistics to be run (default:wilcoxon)

\item[\code{restrict:}] Run the statistics in a subset of the dataset (default: a vector of all TRUE)

\item[\code{multiple.adjust:}] the multiple testing adjustment method (default:BH)

\item[\code{paired:}] wether paired statistics should be run (default:FALSE)

\item[\code{sort:}] return variables sorted by p-value significance (default:TRUE)

\item[\code{verbose:}] print out information indicating progress (default:FALSE)

\item[\code{verbose.step:}] Showing a 1 percent progress.

\item[\code{return.data:}] if (default:FALSE) this returns the statistics of X, otherwise the restricted data subset

\item[\code{accelarate:}] use a turbo method developped by bioQC (default:FALSE). There is an issue when executing in batch.
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{filterNoSignal}{filterNoSignal: Omits the variables with no information}{filterNoSignal}
%
\begin{Description}
This function will clean a dataset from the variables that have no or little information.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
filterNoSignal(X, side = 1, threshold = "auto", verbose = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the dataset to clean

\item[\code{side:}] side=1 means that variables are in the rows. Other than 1 it will transpose the dataset

\item[\code{threshold:}] auto, will compute the first derivate of the median(sd)/x and will find an automatic threshold. When threshold is a numerical it will be used as a threshold and when is something else, will automatically be 0.

\item[\code{verbose:}] print out information when TRUE (default:FALSE)
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{fit}{fit: runs the classifier on a dataset}{fit}
%
\begin{Description}
This function runs a learning experiment based on the classifier
object and the given dataset.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
fit(
  X,
  y,
  clf,
  cross.validate = FALSE,
  lfolds = NULL,
  nfolds = 10,
  parallelize.folds = TRUE,
  compute.importance = TRUE,
  return.all = FALSE,
  log.file = "parallel.log",
  path = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] Dataset to classify

\item[\code{y:}] Variable to predict

\item[\code{clf:}] The classifier object object containing the settings of the classifier

\item[\code{cross.validate:}] Whether or not the classification should be run in
cross-validation mode (default:TRUE)

\item[\code{lfolds:}] The folds to be used for the cross-validation

\item[\code{nfolds:}] The number of folds to use in the cross-validation. If lfolds
are not specified this option allows to set them up (default:10)

\item[\code{parallelize.folds:}] Switch setting the parallelization mode based on
cross-validation folds and nothing else in the algorithm (default:TRUE).
This is much more efficient.

\item[\code{compute.importance:}] The importance of variables in the learning process
during cross-validation can be computed. This is based on data perturbation
similar to the mean decrease accuracy in the random forest algorithm. Moreover,
this gives feature prevalence in models during CV (default:TRUE)

\item[\code{return.all:}] Should all results from the cross-validation steps be
returned. This is usually needed when testing stability of the models
(default:FALSE)

\item[\code{log.file:}] The output file for parallel logs (default:'parallel.log')

\item[\code{path:}] The path where to save temporary data
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An experiment object containing the classifier along with the
classification results as a sub-element
\end{Value}
\inputencoding{utf8}
\HeaderA{generateAllCombinations}{generateAllCombinations}{generateAllCombinations}
%
\begin{Description}
Generate every possible combination of a list of features and evaluate them
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generateAllCombinations(X, y, clf, ind.features.to.keep, sparsity, allFeatures)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{generator\_metal}{\#' Computes best model of a metal clf \#' \#' @description Get best metal model \#' @param X: dataset to classify \#' @param y: variable to predict \#' @param clf: an object containing the different parameters of the classifier \#' @param clf\_res: the result of metal \#' @param k\_penalty: penalty for k \#' @return A list of result of best model for each k, their importance feature of each best model, individuels wrongly classified \#' @export getTheBestMetalModel<- function(clf, clf\_res, X, k\_penalty=0.01, evalToOrder="accuracy\_",selected=1) if(length(clf\_res)==3) clf\_res<-clf\_res\$classifier  pop<-modelCollectionToPopulation(clf\_res\$models) acc <- populationGet\_X(evalToOrder)(pop) k <- populationGet\_X("eval.sparsity")(pop) acc.penalty <- acc-(k*k\_penalty) best.acc <- max(acc.penalty) epsilon <- sqrt(best.acc*(1-best.acc)/ncol(X)) pop2 <- pop[acc.penalty>(best.acc - epsilon)] mod <- getMaxMinPrevalenceModel(pop2,X,selected=selected) return(mod) Generate a metal list of clfs containing information on the generators and unificators}{generator.Rul.metal}
%
\begin{Description}
Generate a metal list of clfs containing information on the generators and unificators
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generator_metal(mat, clf = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mat:}] a language/learner presence matrix that indicates which algorithms and which languages to explore

\item[\code{clf:}] a metal classifier object, with the parameter list.clfs that can be "NULL"
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of clfs
\end{Value}
\inputencoding{utf8}
\HeaderA{getFeaturePrevalence}{Evaluates the prevalence of a list of features in the whole dataset and per each class}{getFeaturePrevalence}
%
\begin{Description}
Evaluate the prevalence of a given model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getFeaturePrevalence(features, X, y = NULL, prop = TRUE, zero.value = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{features:}] a list of features or features indexes for which we wish to compute prevalence

\item[\code{X:}] dataset where to compute the prevalence

\item[\code{y:}] if provided it will also compute hte prevalence per each class (default:NULL)

\item[\code{prop:}] weather to compute the prevalence in number or as a proportion (default:TRUE)

\item[\code{zero.value:}] the value that specifies what is zero. This can be a different than 0 in log transformed data for instance (default = 0)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing the prevalence in the whole dataset as well as classes (if provided)
\end{Value}
\inputencoding{utf8}
\HeaderA{getFitIndividual}{Get the fitting score of an individual object}{getFitIndividual}
%
\begin{Description}
Get the fitting score of an individual object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getFitIndividual(individual)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{individual}] : an individual object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a fitting score
\end{Value}
\inputencoding{utf8}
\HeaderA{getFitModel}{Get the fitting score of a model object}{getFitModel}
%
\begin{Description}
Get the fitting score of a model object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getFitModel(mod)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod}] : a model object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a fitting score
\end{Value}
\inputencoding{utf8}
\HeaderA{getFitModels}{Get the fitting score of a list a models}{getFitModels}
%
\begin{Description}
Get the fitting score of a list a models.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getFitModels(pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop}] : a list of models
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector of fitting scores
\end{Value}
\inputencoding{utf8}
\HeaderA{getFitPopulation}{Get the fitting score of a list of individuals}{getFitPopulation}
%
\begin{Description}
Get the fitting score of a list of individuals.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getFitPopulation(pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop}] : a list of individuals
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector of fitting scores
\end{Value}
\inputencoding{utf8}
\HeaderA{getGraph}{getGraph}{getGraph}
%
\begin{Description}
This function gets a graph of the result of analyseStableModels
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getGraph(mat, X, threshold = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{mat:}] AnalyseStableModels()\$origin

\item[\code{threshold:}] 
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a graph
\end{Value}
\inputencoding{utf8}
\HeaderA{getImportanceFeaturesFBMobjects}{Get objects needed for a merged visualization task combining different experiments from different datasets (different X and y)}{getImportanceFeaturesFBMobjects}
%
\begin{Description}
Here we get the 4 datasets from a given prediction experiment (clf object + X + y) needed for subsequent combination with other 
predition experiments for combined visualization (feature prevalence in FBM + feature importance + featureEffSizes + feature prevalence in groups)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getImportanceFeaturesFBMobjects(
  clf_res,
  X,
  y,
  verbose = TRUE,
  filter.cv.prev = 0.25,
  scaled.importance = FALSE,
  k_penalty = 0.75/100,
  k_max = 0
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf\_res}] The result of a single experiment

\item[\code{X}] The feature table used as input of fit function behind experiments in clf\_res

\item[\code{y}] The target class (binary/continuous)

\item[\code{verbose}] print out informaiton

\item[\code{filter.cv.prev}] keep only features found in at least (default: 0.25, i.e 25 percent) of the cross validation experiments

\item[\code{scaled.importance}] the scaled importance is the importance multipied by the prevalence in the folds. If (default = TRUE) this will be used, the mean mda 
will be scaled by the prevalence of the feature in the folds and ordered subsequently

\item[\code{k\_penalty}] the sparsity penalty needed to select the best models of the population (default:0.75/100).

\item[\code{k\_max}] select the best population below a given threshold. If (default:0) no selection is performed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
list of objects for subsequent combination
\end{Value}
\inputencoding{utf8}
\HeaderA{getIndicesIndividual}{Get the index of the features in a given individual}{getIndicesIndividual}
%
\begin{Description}
Get the indices of the features used in the individuals
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getIndicesIndividual(individual)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{individual}] : an individual object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the indices of the features
\end{Value}
\inputencoding{utf8}
\HeaderA{getIndicesPopulation}{Get the indices of the features used in a population of individuals}{getIndicesPopulation}
%
\begin{Description}
Get the indices of the features used in a population of individuals
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getIndicesPopulation(pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop}] : a list of individuals
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a matrix of indices (rows), and individuals (cols)
\end{Value}
\inputencoding{utf8}
\HeaderA{getMaxMinPrevalenceModel}{Get the model that has the highest minimal prevalence in its features}{getMaxMinPrevalenceModel}
%
\begin{Description}
Get the model that has the highest minimal prevalence in its features
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getMaxMinPrevalenceModel(pop, X = NULL, evalToOrder = "fit_", selected = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population of model objects

\item[\code{X:}] dataset where to compute the prevalence

\item[\code{evalToOrder:}] which score should we use to order the models and select them (default:fit\_)

\item[\code{selected:}] the number of selected models (default:0). If 0, everything is returned.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model or a list of model objects
\end{Value}
\inputencoding{utf8}
\HeaderA{getModelScore}{Computes the \textasciicircum{}y score of the model}{getModelScore}
%
\begin{Description}
Returns the \textasciicircum{}y score of the model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getModelScore(mod, X, clf, force.re.evaluation = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model object where the score will be computed

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{force.re.evaluation:}] we recompute the score (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector containing the predicted \textasciicircum{}y score for each observation
\end{Value}
\inputencoding{utf8}
\HeaderA{getNBestModels}{Get the models from a classifier result for each k-sparsity}{getNBestModels}
%
\begin{Description}
Get the N best models from a classifier result for each k-sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getNBestModels(
  obj,
  significance = FALSE,
  by.k.sparsity = TRUE,
  k.penalty = 0,
  n.best = 5,
  single.best = FALSE,
  single.best.cv = TRUE,
  single.best.k = NULL,
  max.min.prevalence = FALSE,
  X = NULL,
  verbose = FALSE,
  evalToOrder = "fit_",
  return.population = FALSE,
  unique.control = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] the classifier result output from the function fit. This can also be a ModelCollection or Population object

\item[\code{significance:}] if TRUE, (default:FALSE) a statistical test will be applied to find the lowest threshold that will delimit the window
of the best models. If FALSE, the models will be selected according to the rest of the criteria.

\item[\code{by.k.sparsity:}] if TRUE (default:TRUE), the filtering will be performed for each sparsity level

\item[\code{k.penalty:}] (default:0), it will penalize the models with large sparsity if different, when by.k.sparsity is set to TRUE

\item[\code{n.best:}] the number of best models to be returned for each sparsity if by.k.sparsity is set to TRUE or for the whole population 
otherwise (default:5).

\item[\code{nbest:}] the number of best models we wish to get from the population, per each sparsity or not. If there are less best models then this
number, less will be returned

\item[\code{single.best:}] if TRUE, this will return the best model of all (default:FALSE) and the n.best will be set to 1.

\item[\code{single.best.cv:}] if single.best is TRUE, we could chose the best model based on data from cross validation (default:TRUE) and in this 
case obj should be an experiment or from empirical results not in CV.

\item[\code{single.best.k:}] if single.best is TRUE, we could chose the best model of a given sparsity that is specified by a number here. 
If this value is specified (default:NULL), then this will de-actvate single.best.cv.

\item[\code{max.min.prevalence:}] if TRUE (default:FALSE), the best models will be selected based on their performance but also on the prevalence of 
the features that compose it.

\item[\code{X:}] the dataset to be learned (default:NULL). This is neeeded when max.min.prevalence is set to TRUE.

\item[\code{verbose:}] provide more information about execution (default = FALSE)

\item[\code{evalToOrder:}] which attribute of the model object should we use to order the models and select them (default:fit\_)

\item[\code{return.population:}] if set to TRUE (default:FALSE), the result will be send as a population of models

\item[\code{unique.control:}] if set to TRUE (default:TRUZ), we correct the population so that no dupplication of models takes place
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of model objects or a model when it is a single one or a model collection
\end{Value}
\inputencoding{utf8}
\HeaderA{getSign}{Evaluates the sign for a given feature this is the old getMgsVsTraitSignDiscr function}{getSign}
%
\begin{Description}
Evaluates the sign for a given feature this is the old getMgsVsTraitSignDiscr function.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getSign(X, y, clf = NULL, parallel.local = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{parallel.local:}] weather or not to run in //
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector of +1 \& -1 for each variable
\end{Value}
\inputencoding{utf8}
\HeaderA{get\_IndividualToBeMutated}{Return list of individuals to mutate}{get.Rul.IndividualToBeMutated}
%
\begin{Description}
Wraper function that returns the list of individuals that are going to go through 
the mutate function (normaly taged with \LinkA{tag\_SelectRandom}{tag.Rul.SelectRandom})
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_IndividualToBeMutated(pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] population list
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of individuals (= a population) containing all the individuals selected for mutation
\end{Value}
\inputencoding{utf8}
\HeaderA{get\_Parents}{Return list of parents}{get.Rul.Parents}
%
\begin{Description}
Wraper function that returns the list of parents (normaly taged with 
\LinkA{tag\_SelectRandom}{tag.Rul.SelectRandom})
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_Parents(pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] population list
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of individuals (= a population) containing all the selected parents
\end{Value}
\inputencoding{utf8}
\HeaderA{glmnetRR}{Solve with GLMNET and create models}{glmnetRR}
%
\begin{Description}
Create Models by applying randomized roundings on the a solution given by GLMNET
\end{Description}
%
\begin{Usage}
\begin{verbatim}
glmnetRR(clf, X, y)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{ibd}{Inflammatory Bowel Disease (frequencies) from the MetaHIT study}{ibd}
\keyword{bowel}{ibd}
\keyword{disease,}{ibd}
\keyword{inflamatory}{ibd}
\keyword{microbiome,}{ibd}
\keyword{species}{ibd}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/
This is a list containing two elements: (i) the X data matrix with 1045 species and 396 observations and (ii) patient class = -1 (n=148) and healthy controls (n=248)
\end{Description}
%
\begin{Author}
Nielsen, H Bjørn, Mathieu Almeida, Agnieszka Sierakowska Juncker, Simon Rasmussen, Junhua Li, Shinichi Sunagawa, Damian R Plichta, et al “Identification and assembly of genomes and genetic elements in complex metagenomic samples without using reference genomes.” Nature biotechnology (July 6, 2014): 1–11.
\end{Author}
\inputencoding{utf8}
\HeaderA{index2names}{index2names}{index2names}
%
\begin{Description}
Transforms feature indexes into feature names
\end{Description}
%
\begin{Usage}
\begin{verbatim}
index2names(X, var.ind)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the dataset

\item[\code{var.ind:}] the feature index vector
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the names of the features
\end{Value}
\inputencoding{utf8}
\HeaderA{individual}{Creates an object individual}{individual}
%
\begin{Description}
Creates an object individual
\end{Description}
%
\begin{Usage}
\begin{verbatim}
individual(
  X,
  y,
  clf,
  coeffs = NULL,
  ind = NULL,
  eval.all = FALSE,
  signs = NULL,
  obj = NULL,
  res_clf = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{clf:}] the object containing the classifier information

\item[\code{ind:}] the indexes of the variables forming the individual could be null if we give the function a dense vector (via the coeff parameter) or if we also want to generate the individual

\item[\code{coeffs:}] the coefficients of the model, it could be a dense vector (in this case, ind need to be null), or it could be only the non zero values, or if it's null a new individual will be genrated

\item[\code{obj:}] an object to be incorporated in the model (default:NULL). We use this usually for SOTA.

\item[\code{res\_clf:}] if provided information on mda etc can be found and transmitted to the model object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an individual (model) object
\end{Value}
\inputencoding{utf8}
\HeaderA{isClf}{Evaluates wether an object is a classifier}{isClf}
%
\begin{Description}
Evaluates wether an object is a classifier
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isClf(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{isclose}{tests weather two values are close}{isclose}
%
\begin{Description}
Asserts wether two vectors of the same length are close in value
below a given threshold
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isclose(x, y, e = 1e-10)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x:}] condition to be tested

\item[\code{y:}] message to be printed
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE when the distance of two numbers is smaller than a given value
\end{Value}
\inputencoding{utf8}
\HeaderA{isExperiment}{Evaluates wether an object is an experiment}{isExperiment}
%
\begin{Description}
Evaluates wether an object is an experiment
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isExperiment(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is an experiment
\end{Value}
\inputencoding{utf8}
\HeaderA{isLearnerSota}{Evaluates wether an object is a model SOTA SVM}{isLearnerSota}
%
\begin{Description}
Evaluates wether a learner is SOTA or not
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isLearnerSota(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a SOTA learner
\end{Value}
\inputencoding{utf8}
\HeaderA{isModel}{Evaluates wether an object is a model}{isModel}
%
\begin{Description}
Evaluates wether an object is a model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModel(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelBTR}{Evaluates wether an object is a model BTR}{isModelBTR}
%
\begin{Description}
Evaluates wether an object is a model of type BTR
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelBTR(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model BTR
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelCollection}{Evaluates wether an object is a model collection objecct}{isModelCollection}
%
\begin{Description}
Evaluates wether an object is a model collection objecct
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelCollection(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model collection objecct
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelSota}{Evaluates wether an object is a model SOTA}{isModelSota}
%
\begin{Description}
Evaluates wether an object is a model of type sota
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelSota(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model sota
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelSotaGLMNET}{Evaluates wether an object is a model SOTA GLMNET}{isModelSotaGLMNET}
%
\begin{Description}
Evaluates wether an object is a model of type sota
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelSotaGLMNET(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model sota GLMNET
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelSotaRF}{Evaluates wether an object is a model SOTA RF}{isModelSotaRF}
%
\begin{Description}
Evaluates wether an object is a model of type sota
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelSotaRF(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model sota RF
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelSotaSVM}{Evaluates wether an object is a model SOTA SVM}{isModelSotaSVM}
%
\begin{Description}
Evaluates wether an object is a model of type sota
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelSotaSVM(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model sota SVM
\end{Value}
\inputencoding{utf8}
\HeaderA{isModelTerda}{Evaluates wether an object is a model BTR Terda}{isModelTerda}
%
\begin{Description}
Evaluates wether an object is a model of type BTR
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isModelTerda(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a model BTR Terda
\end{Value}
\inputencoding{utf8}
\HeaderA{isPopulation}{Evaluates wether an object is a population of models}{isPopulation}
%
\begin{Description}
Evaluates wether an object is a population of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
isPopulation(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the object is a population
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfDenseVecToListOfModels}{Builds a model object from a list of vector coefficients}{listOfDenseVecToListOfModels}
%
\begin{Description}
Builds a model object from a list of vector coefficients.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfDenseVecToListOfModels(X, y, clf, v, lobj = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{clf:}] classifier

\item[\code{v:}] list of vectors of coeffs. For example, v=list( c(0.0,1.0,0.0,-1.0) , c(1.0,1.0,0.0,0.0) , c(0.0,1.0,1.0,-1.0) )

\item[\code{lobj:}] a list of objects to add as elements in the model objects if not null (default:NULL)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an model object
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfDenseVecToModelCollection}{Builds a list of dense vector coefficients from a list of models}{listOfDenseVecToModelCollection}
%
\begin{Description}
Builds a list of dense vector coefficients from a list of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfDenseVecToModelCollection(clf, X, y, v)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] classifier

\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{v:}] list of dense vectors
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a model collection
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfModels2ModelCollection}{listOfModels2ModelCollection}{listOfModels2ModelCollection}
%
\begin{Description}
Structures a list of predomics objects into a structured collection by k\_sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfModels2ModelCollection(pop, nBest = NA)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] is population (a list) of predomics objects

\item[\code{nBest:}] number of elements to return for each sparsity (default:NA)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an model collection object
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfModelsToDenseCoefMatrix}{listOfModelsToDenseCoefMatrix}{listOfModelsToDenseCoefMatrix}
%
\begin{Description}
For each model in the list of models it will convert to dense format and convert to a data.frame
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfModelsToDenseCoefMatrix(
  clf,
  X,
  y,
  list.models,
  rm.empty = TRUE,
  order.row = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier object

\item[\code{X:}] the dataset

\item[\code{y:}] the class vector

\item[\code{list.model:}] a list of model objects

\item[\code{rm.empty:}] remove null models in the list if any (default:TRUE)

\item[\code{order.row:}] order rows by occurence (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an data frame with model coefficients in rows
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfModelsToListOfDenseVec}{Builds a list of dense vector coefficients from a list of models}{listOfModelsToListOfDenseVec}
%
\begin{Description}
Builds a list of dense vector coefficients from a list of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfModelsToListOfDenseVec(clf, X, y, list.models)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] classifier

\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{list.models:}] list of models
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of dense vectors of coefficient
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfModelsToListOfSparseVec}{Builds a list of sparse vector coefficients from a list of models}{listOfModelsToListOfSparseVec}
%
\begin{Description}
Builds a list of sparse vector coefficients from a list of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfModelsToListOfSparseVec(list.models)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.models:}] list of models
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of dense vectors of coefficient
\end{Value}
\inputencoding{utf8}
\HeaderA{listOfSparseVecToListOfModels}{listOfSparseVecToListOfModels}{listOfSparseVecToListOfModels}
%
\begin{Description}
Converts an list of "SparseVec" objects onto a list of predomics objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listOfSparseVecToListOfModels(X, y, clf, v, lobj = NULL, eval.all = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{clf:}] classifier

\item[\code{v:}] list of vectors of coeffs. For example, v=list( c(0.0,1.0,0.0,-1.0) , c(1.0,1.0,0.0,0.0) , c(0.0,1.0,1.0,-1.0) )

\item[\code{lobj:}] a list of objects to add as elements in the model objects if not null (default:NULL)

\item[\code{eval.all:}] evaluate population (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an model object
\end{Value}
\inputencoding{utf8}
\HeaderA{loadPopulation}{Load a population from a file}{loadPopulation}
%
\begin{Description}
This function is used to load a population from a file on your disk (it must be in your working directory)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
loadPopulation(fileName)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{fileName:}] The name of the file were the population is stored
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population object
\end{Value}
\inputencoding{utf8}
\HeaderA{loadResults}{Load the results of a fit}{loadResults}
%
\begin{Description}
Load the results of a fit
\end{Description}
%
\begin{Usage}
\begin{verbatim}
loadResults(fileName)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{LPO\_best\_models}{Compute the cross-validation of leave one out for test stability}{LPO.Rul.best.Rul.models}
%
\begin{Description}
Compute the cross-validation emprirical and generalization scores.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
LPO_best_models(X, y, clf, p = 1, lfolds = NULL, return.all = FALSE, nk = 20)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] clf

\item[\code{lfolds:}] leave one out folds for cross-validation

\item[\code{return.all:}] return all results from the crossvalidation for feature stability testing
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list containing generalisation scores for each fold as well as a matrix with the mean values.
\end{Value}
\inputencoding{utf8}
\HeaderA{make.counter}{Function used to create the counter for building clf\$experiment\$id}{make.counter}
%
\begin{Description}
Function used to create the counter for building clf\$experiment\$id
\end{Description}
%
\begin{Usage}
\begin{verbatim}
make.counter()
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{makeFeatureAnnot}{Prints as text the detail on a given experiment along with summarized results (if computed)}{makeFeatureAnnot}
%
\begin{Description}
This function takes a population of models and creates a table with annotation on the features, 
such as prevalence in the models and dataset as well as different statistics
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeFeatureAnnot(pop, X, y, clf)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population of models

\item[\code{X:}] the X dataset where to compute the abundance and prevalence

\item[\code{y:}] the target class

\item[\code{clf:}] an object containing the different parameters of the classifier
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list with two data.frames one containing the coefficients per each model and the other a data.frame on the features
\end{Value}
\inputencoding{utf8}
\HeaderA{makeFeatureModelPrevalenceNetworkCooccur}{Prints as text the detail on a given experiment along with summarized results (if computed)}{makeFeatureModelPrevalenceNetworkCooccur}
%
\begin{Description}
This function will use the coocur package to compute the co-occurance of features in a population of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeFeatureModelPrevalenceNetworkCooccur(
  pop.noz,
  feature.annot,
  alpha = 0.05,
  verbose = TRUE,
  layout = "circlular"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop.noz:}] a data.frame of in features in the rows and models in the columns. 
This table contains the feature coefficients in the models and is obtained by makeFeatureAnnot()

\item[\code{feature.annot:}] a data frame with annotation on features obtained by makeFeatureAnnot()

\item[\code{alpha:}] the significane p-value of the co-occurance.

\item[\code{verbose:}] print out information during run

\item[\code{layout:}] the network layout by default is circular (layout\_in\_circle) and will be a weighted Fruchterman-Reingold otherwise
\end{ldescription}
\end{Arguments}
%
\begin{Value}
plots a graph
\end{Value}
\inputencoding{utf8}
\HeaderA{makeFeatureModelPrevalenceNetworkMiic}{Prints as text the detail on a given experiment along with summarized results (if computed)}{makeFeatureModelPrevalenceNetworkMiic}
%
\begin{Description}
This function will use the miic package to compute the co-occurance of features in a population of models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeFeatureModelPrevalenceNetworkMiic(
  pop.noz,
  feature.annot,
  cor.th = 0.3,
  verbose = TRUE,
  layout = "circlular"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop.noz:}] a data.frame of in features in the rows and models in the columns. 
This table contains the feature coefficients in the models and is obtained by makeFeatureAnnot()

\item[\code{feature.annot:}] a data frame with annotation on features obtained by makeFeatureAnnot()

\item[\code{cor.th:}] a threshold abtained on the partial correlation value

\item[\code{verbose:}] print out information during run

\item[\code{layout:}] the network layout by default is circular (layout\_in\_circle) and will be a weighted Fruchterman-Reingold otherwise
\end{ldescription}
\end{Arguments}
%
\begin{Value}
plots a graph
\end{Value}
\inputencoding{utf8}
\HeaderA{mergeMeltBestScoreCV}{mergeMeltBestScoreCV}{mergeMeltBestScoreCV}
%
\begin{Description}
mergeMeltBestScoreCV returns a list of data frames that contain the best performance of the different learners without any focus on sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mergeMeltBestScoreCV(
  list.results.digest,
  k_catalogue = NULL,
  score = "auc_",
  penalty = 0,
  min.kfold.nb = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.results.digest:}] a list of digest objects one for each learner used. For example, list(res.terda.digest, res.terga.digest, res.terbeam.digest)

\item[\code{k\_catalogue:}] the k\_catalogue that will serve to build the result matrix (default:NULL)

\item[\code{score:}] the name of the score that needs to be used for the whole dataset visualization.

\item[\code{min.kfold.nb:}] wether we should restrict all experiments in the smallest number of k-folds of a comparative analyses (default = FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Merge a list of cross validation scores form digest results
\end{Details}
%
\begin{Value}
a list of two data.frames
\end{Value}
\inputencoding{utf8}
\HeaderA{mergeMeltImportanceCV}{mergeMeltImportanceCV}{mergeMeltImportanceCV}
%
\begin{Description}
mergeMeltImportanceCV returns a list of data frames that contain the feature importance of the different learners without any focus on sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mergeMeltImportanceCV(
  list.results,
  filter.cv.prev = 0.5,
  min.kfold.nb = FALSE,
  type = "mda",
  learner.grep.pattern = "*",
  nb.top.features = 25,
  feature.selection = NULL,
  fixed.order = FALSE,
  scaled.importance = TRUE,
  make.plot = TRUE,
  main = FALSE,
  cv.prevalence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.results.digest:}] a list of digest objects one for each learner used. For example, list(res.terda.digest, res.terga.digest, res.terbeam.digest)

\item[\code{filter.cv.prev:}] filter variable for each learner based on the appearence prevalence in the cross validation.

\item[\code{min.kfold.nb:}] wether we should restrict all experiments in the smallest number of k-folds of a comparative analyses (default = FALSE)

\item[\code{type:}] the type of importance "mda (mean decreased accuracy)" or "pda (prevalence decreased accuracy)" (default = mda)

\item[\code{learner.grep.pattern:}] select a subset of learners using a grep pattern (default:"*")

\item[\code{nb.top.features:}] the number of top features to focus on the plot

\item[\code{feature.selection:}] the names of the features to be selected (default:NULL)

\item[\code{fixed.order:}] if the order of features in the plot should follow the feature selection one (default = FALSE)

\item[\code{scaled.importance:}] the scaled importance is the importance multipied by the prevalence in the folds. If (default = TRUE) this will be used, the mean mda 
will be scaled by the prevalence of the feature in the folds and ordered subsequently

\item[\code{make.plot:}] make a plot for all the learners

\item[\code{main:}] should add the title to the graph for correct alignment (default:FALSE)

\item[\code{cv.prevalence:}] wether or not to plot the distribution of the prevalence of the feature in the top-models for each k-fold in the graph (default:FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Merge a list of cross validation scores form digest results
\end{Details}
%
\begin{Value}
a list of several data.frames and a ggplot object
\end{Value}
\inputencoding{utf8}
\HeaderA{mergeMeltScoreCV}{mergeMeltScoreCV}{mergeMeltScoreCV}
%
\begin{Description}
mergeMeltScoreCV returns a list of data frames that contain the performance of each digest in the list with their sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mergeMeltScoreCV(
  list.results.digest,
  k_catalogue,
  generalization = TRUE,
  score = "auc_"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.results.digest:}] a list of digest objects one for each learner used. For example, list(res.terda.digest, res.terga.digest, res.terbeam.digest)

\item[\code{k\_catalogue:}] the k\_catalogue that will serve to build the result matrix

\item[\code{generalization:}] get results from CV generalization (if TRUE) or empirical otherwise (default: TRUE)

\item[\code{score:}] the name of the score that needs to be used for the whole dataset visualization.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Merge a list of cross validation scores form digest results
\end{Details}
%
\begin{Value}
a list of two data.frames
\end{Value}
\inputencoding{utf8}
\HeaderA{mergeMeltScoreEmpirical}{mergeMeltScoreEmpirical}{mergeMeltScoreEmpirical}
%
\begin{Description}
mergeMeltScoreEmpirical returns a data frames that contain the performance of each digest in the list with their sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mergeMeltScoreEmpirical(list.results.digest, k_catalogue, score = "fit_")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.results.digest:}] a list of digest objects one for each learner used. For example, list(res.terda.digest, res.terga.digest, res.terbeam.digest)

\item[\code{k\_catalogue:}] the k\_catalogue that will serve to build the result matrix

\item[\code{score:}] which score is to be used for value (default: fit\_)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Merge a list of empirical scores form digest results
\end{Details}
%
\begin{Value}
a data.frame
\end{Value}
\inputencoding{utf8}
\HeaderA{mergeResults}{mergeResults}{mergeResults}
%
\begin{Description}
mergeResults returns a list of data frames that contain the performance of each digest in the list with their sparsity.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mergeResults(
  list.results,
  sparsity = NULL,
  penalty = 0.001,
  best.k = NULL,
  colors = NULL,
  pch = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{list.results:}] a list of Experiment objects one for each learner used. For example, list(res.terda, res.terga, res.terbeam)

\item[\code{sparsity:}] Sometimes a given method will have results with somehow different sparsity. This param will allow to set the catalogue of sparsity

\item[\code{best.k:}] a vector defining wether a given k should be used to set the best model selection (default:NULL).

\item[\code{colors:}] a vector defining the colors to be used in the graphics. If not specified they will be set by default. (default:NULL).

\item[\code{pch:}] a vector defining the shape of the points to be used in the graphics. If not specified they will be set by default. (default:NULL).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Merge a list of Scores form a digest results
\end{Details}
%
\begin{Value}
list of data.frames and lists
\end{Value}
\inputencoding{utf8}
\HeaderA{metal}{metal: metal searching algorithm}{metal}
%
\begin{Description}
metal is a model search algorithm on a list of beam search approach and get the populations into GA.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
metal(
  sparsity = 1:10,
  max.nb.features = 1000,
  popSaveFile = "NULL",
  saveFiles = FALSE,
  pathSave = "NULL",
  language = "mix",
  scoreFormula = scoreRatio,
  epsilon = "NULL",
  objective = "auc",
  k_penalty = 0,
  evalToFit = "accuracy_",
  estimate_coefs = FALSE,
  intercept = "NULL",
  testAllSigns = FALSE,
  plot = FALSE,
  verbose = TRUE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  parallelize.folds = TRUE,
  nCores = 10,
  seed = "NULL",
  experiment.id = "NULL",
  experiment.description = "NULL",
  experiment.save = "nothing",
  list.clfs = "NULL",
  unificator.method = "terga2",
  unificator.evolver = "v2m_new"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"terinter")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{max.nb.features:}] focuses only on the subset of top most significant features (default:1000)

\item[\code{popSaveFile:}] (??)

\item[\code{saveFiles:}] ??

\item[\code{scoreFormula:}] a Function that contains the ratio Formula or other specific ones

\item[\code{epsilon:}] a small value to be used with the ratio language (useCustomLanguage) (default: NULL). When null it is going to be calculated by the minimum value of X divided by 10.

\item[\code{objective:}] this can be auc, cor or aic. Terga can also predict regression, other than class prediction. (default:auc)

\item[\code{estimate\_coefs:}] non ternary solution for the aic objective (default:FALSE)

\item[\code{evalToFit:}] The model performance attribute to use as fitting score (default:"fit\_"). Other choices are c("auc\_","accuracy\_","precision\_","recall\_","f\_score\_")

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{intercept:}] (??) (default:NULL)

\item[\code{testAllSigns:}] ??

\item[\code{plot:}] plot graphics indicating the evolution of the simulation (default:FALSE)

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print debug information (default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{parallelize.folds:}] parallelize folds when cross-validating (default:TRUE)

\item[\code{nCores:}] the number of cores to execute the program. If nCores=1 than the program runs in a non parallel mode

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"

\item[\code{list.clfs:}] list of Genetor and Unificator

\item[\code{unificator.method:}] the default unificator is a terga2. Other one specified will yield a stop of the program.

\item[\code{unificator.evolver:}] the default evolve method used by the unificator which is by default a terga2.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{modelCollectionToPopulation}{Transform a model collection to a population (or list of model objects)}{modelCollectionToPopulation}
%
\begin{Description}
Transform a model collection to a population (or list of model objects)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
modelCollectionToPopulation(mod.collection)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod.collection:}] a modelCollection object organized by k\_sparsity
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{modelToDenseVec}{Transform the model object onto dense format (long) one}{modelToDenseVec}
%
\begin{Description}
Builds a model object based on model that is in the dense (long) format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
modelToDenseVec(natts, mod)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{natts:}] the number of attributes

\item[\code{mod:}] a predomics model object
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a dense (long) format model
\end{Value}
\inputencoding{utf8}
\HeaderA{multipleRR}{multipleRR}{multipleRR}
%
\begin{Description}
computes multiple randomized rounding for a given vector of wi
\end{Description}
%
\begin{Usage}
\begin{verbatim}
multipleRR(clf, X, y, w, n, remove.zero.vec = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier parameter object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{w:}] a vector of wi coefficients

\item[\code{n:}] number of round roundings to compute

\item[\code{remove.zero.vec:}] whether to remove the zero vectors
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an population of dense vectors
\end{Value}
\inputencoding{utf8}
\HeaderA{multipleRR\_par}{multipleRR\_par}{multipleRR.Rul.par}
%
\begin{Description}
computes in parallel multiple randomized rounding for a given vector of wi
\end{Description}
%
\begin{Usage}
\begin{verbatim}
multipleRR_par(clf, X, y, w, n, remove.zero.vec = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier parameter object

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{w:}] a vector of wi coefficients

\item[\code{n:}] number of round roundings to compute

\item[\code{remove.zero.vec:}] whether to remove the zero vectors
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an population of dense vectors
\end{Value}
\inputencoding{utf8}
\HeaderA{mutate}{Changes feature indexes in a given percentage of models.}{mutate}
%
\begin{Description}
This function is used in terga1 will create new combinations of features based of existing ones from the parents.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mutate(clf, pop, selection, seed = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier parameter object

\item[\code{pop:}] A population (i.e. list) of index vectors

\item[\code{selection:}] Indexes of the population pointing to the subset of the models to be changed

\item[\code{seed:}] For reproductibility purpose to fix the random generator number.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population of models among which the mutated ones
\end{Value}
\inputencoding{utf8}
\HeaderA{myAssert}{Asserts a condition and prints a message or stops the block}{myAssert}
%
\begin{Description}
Asserts a condition and prints a message or stops the block
\end{Description}
%
\begin{Usage}
\begin{verbatim}
myAssert(condition, message, stop = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{condition:}] condition to be tested

\item[\code{message:}] message to be printed

\item[\code{stop:}] if TRUE stop the block
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{myAssertNotNullNorNa}{Asserts the existance of an object and prints a message or stops the block}{myAssertNotNullNorNa}
%
\begin{Description}
Asserts the existance of an object and prints a message or stops
the block
\end{Description}
%
\begin{Usage}
\begin{verbatim}
myAssertNotNullNorNa(obj, message = "", stop = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] condition to be tested

\item[\code{message:}] message to be printed

\item[\code{stop:}] if TRUE stop the block
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{names2index}{names2index}{names2index}
%
\begin{Description}
Transforms feature names feature indexes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
names2index(X, var.names)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the dataset

\item[\code{var.names:}] the feature names vector
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the index of the features
\end{Value}
\inputencoding{utf8}
\HeaderA{normModelCoeffs}{Normalize the model coefficients needed for the plot}{normModelCoeffs}
%
\begin{Description}
Normalize the model coefficients needed for the plot
\end{Description}
%
\begin{Usage}
\begin{verbatim}
normModelCoeffs(mod, X, y, sort.features = FALSE, sort.ind = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to plot

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{sort.features:}] wether the features need to be sorted by correlation with 'y' or not (default:FALSE)

\item[\code{sort.ind:}] computing sorting can take time if computed for every model and can be computed outside the function and passed as a parameter
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the normalized coefficients
\end{Value}
\inputencoding{utf8}
\HeaderA{obesity}{Obesity (frequencies) from the MetaHIT study}{obesity}
\keyword{microbiome,}{obesity}
\keyword{obesity,}{obesity}
\keyword{species}{obesity}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/
This is a list containing two elements: (i) the X data matrix with 1045 species and 292 observations and (ii) patient class = -1 (n=167) and healthy controls (n=96).
Caution, this dataset has also a class 0 with overweight patients, which needs to be omited from both X and y
\end{Description}
%
\begin{Author}
Le Chatelier, Emmanuelle, Trine Nielsen, Junjie Qin, Edi Prifti, Falk Hildebrand, Gwen Falony, Mathieu Almeida, et al “Richness of human gut microbiome correlates with metabolic markers.” Nature 500, no. 7464 (April 9, 2014): 541–546.
\end{Author}
\inputencoding{utf8}
\HeaderA{plotAbundanceByClass}{Plots the prevalence of a list of features in the whole dataset and per each class}{plotAbundanceByClass}
%
\begin{Description}
Plots the abundance of a given number of features for each class and tests significance
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotAbundanceByClass(
  features,
  X,
  y,
  topdown = TRUE,
  main = "",
  plot = TRUE,
  col.pt = c("deepskyblue4", "firebrick4"),
  col.bg = c("deepskyblue1", "firebrick1")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{features:}] a list of features or features indexes for which we wish to compute prevalence

\item[\code{X:}] dataset where to compute the prevalence

\item[\code{y:}] if provided it will also compute hte prevalence per each class (default:NULL)

\item[\code{topdown:}] showing features from top-down or the other way around (default:TRUE)

\item[\code{main:}] main title (default:none)

\item[\code{plot:}] if TRUE this provides a plot, otherwise will return different metrics such as prevalence and enrichment statistics

\item[\code{col.pt:}] colors for the point border (-1:deepskyblue4, 1:firebrick4)

\item[\code{col.bg:}] colors for the point fill (-1:deepskyblue1, 1:firebrick1)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a ggplot object
\end{Value}
\inputencoding{utf8}
\HeaderA{plotAUC}{Analyze the results from a given classifier}{plotAUC}
%
\begin{Description}
Analyze the results from a given classifier.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotAUC(score, y, main = "", ci = TRUE, percent = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{score:}] this is the y\textasciicircum{} of a given model

\item[\code{y:}] the class to be predted

\item[\code{main:}] title of the graph

\item[\code{ci:}] the point shape for the graph

\item[\code{percent:}] color for the graph
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a roc object
\end{Value}
\inputencoding{utf8}
\HeaderA{plotAUCg}{Plot the AUC of a given classifier}{plotAUCg}
%
\begin{Description}
Analyze the results from a given classifier.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotAUCg(mod = NULL, score, y, main = "", ci = TRUE, show.intercept = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a predomics model object (default = NULL)

\item[\code{score:}] this is the y\textasciicircum{} of a given model

\item[\code{y:}] the class to be predicted

\item[\code{main:}] title of the graph

\item[\code{ci:}] the point shape for the graph

\item[\code{show.intercept:}] plot or not the intercept on the graph (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a ggplot object
\end{Value}
\inputencoding{utf8}
\HeaderA{plotComparativeBestCV}{Plots a graph for a given score}{plotComparativeBestCV}
%
\begin{Description}
plotComparativeCV plots a digested.results data object for a given score.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotComparativeBestCV(
  digested.results,
  ylim = c(0.5, 1),
  generalization = TRUE,
  score = "auc_",
  ci = TRUE,
  main = ""
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{digested.results:}] a list of data.frames containing performance results from a lists of learners. This data object is returned by the function merge\_digestScores()

\item[\code{ylim:}] y-axis zoom in the plot

\item[\code{score:}] default (auc\_) score for the cross-validation representation

\item[\code{main:}] name of the graphic
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A ggplot graphs
\end{Value}
\inputencoding{utf8}
\HeaderA{plotComparativeCV}{Plots a graph for a given score}{plotComparativeCV}
%
\begin{Description}
plotComparativeCV plots a digested.results data object for a given score.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotComparativeCV(
  digested.results,
  ylim = c(0.5, 1),
  generalization = TRUE,
  score = "auc_",
  ci = TRUE,
  main = ""
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{digested.results:}] a list of data.frames containing performance results from a lists of learners. This data object is returned by the function merge\_digestScores()

\item[\code{ylim:}] y-axis zoom in the plot

\item[\code{generalization:}] when (default:TRUE) then the generalization score will be used

\item[\code{score:}] default (auc\_) score for the cross-validation representation

\item[\code{ci:}] should the confidence intereval be plotted (default:TRUE)

\item[\code{main:}] name of the graphic
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A ggplot graphs
\end{Value}
\inputencoding{utf8}
\HeaderA{plotComparativeEmpiricalScore}{Plots a graph for a given score}{plotComparativeEmpiricalScore}
%
\begin{Description}
plotComparativeEmpiricalScore plots a digested.results data object for a given score.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotComparativeEmpiricalScore(
  digested.results,
  ylim = c(0.5, 1),
  score = "auc_",
  main = ""
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{digested.results:}] a list of data.frames containing performance results from a lists of learners. This data object is returned by the function merge\_digestScores()

\item[\code{ylim:}] y-axis zoom in the plot

\item[\code{score:}] default (auc\_) score

\item[\code{main:}] name of the graphic
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A ggplot graphs
\end{Value}
\inputencoding{utf8}
\HeaderA{plotComparativeResults}{Plot performance scores for multiple learners}{plotComparativeResults}
%
\begin{Description}
plotComparativeResults plots a digested.results data object to compare performance results between different learners.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotComparativeResults(
  digested.results,
  plot = TRUE,
  ylim = c(0.5, 1),
  best = FALSE,
  ci = FALSE,
  main = "",
  mode = "classification"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{digested.results:}] a list of data.frames containing performance results from a lists of learners. This data object is returned by the function merge\_digestScores()

\item[\code{ylim:}] y-axis zoom in the plot

\item[\code{best:}] a swith to plot the best values instead of declining by k\_sparsity

\item[\code{main:}] name of the graphic

\item[\code{mode:}] either classification or regression (default:classification)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list of ggplot graphs if plot is set to FALSE and a pannel organized graph otherwise.
\end{Value}
\inputencoding{utf8}
\HeaderA{plotComparativeResultsBest}{Plot performance scores for multiple learners}{plotComparativeResultsBest}
%
\begin{Description}
plotComparativeResultsBest plots a digested.results data object to compare performance results between different learners focusing at the best model.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotComparativeResultsBest(digested.results, plot = TRUE, ylim = c(0.5, 1))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{digested.results:}] a list of data.frames containing performance results from a lists of learners. This data object is returned by the function merge\_digestScores()

\item[\code{ylim:}] y-axis zoom in the plot
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list of ggplot graphs if plot is set to FALSE and a pannel organized graph otherwise.
\end{Value}
\inputencoding{utf8}
\HeaderA{plotFeatureModelCoeffs}{Plots the prevalence of a list of features in the whole dataset and per each class}{plotFeatureModelCoeffs}
%
\begin{Description}
Plots the coefficients of subset of features in the models where they are found
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotFeatureModelCoeffs(
  feat.model.coeffs,
  topdown = TRUE,
  main = "",
  col = c("deepskyblue1", "white", "firebrick1"),
  vertical.label = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{feat.model.coeffs:}] feature vs. model coeffient table

\item[\code{topdown:}] showing features from top-down or the other way around (default:TRUE)

\item[\code{main:}] main title (default:none)

\item[\code{col:}] colors to be used for the coeffients (default: -1 = deepskyblue1, 0 = white, 1 = firebrick1)

\item[\code{vertical.label:}] wether the x-axis labels should be vertical or not (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a ggplot object
\end{Value}
\inputencoding{utf8}
\HeaderA{plotImportanceFeaturesFBMobjects}{Visualize a list containing outouts of getImportanceFeaturesFBMobjects}{plotImportanceFeaturesFBMobjects}
%
\begin{Description}
Here we combine the 4 datasets generated by getImportanceFeaturesFBMobjects function from different prediction experiments (clf object + X + y) ; designed to combine predomics results with different X,y source data
for unified visualization (feature prevalence in FBM, feature importance, feature effect size across groups, feature prevalence across groups)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotImportanceFeaturesFBMobjects(
  FBMobjList,
  verbose = TRUE,
  nb.top.features = 100,
  makeplot = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{FBMobjList}] List of outputs of getImportanceFeaturesFBMobjects function (1 list per experiment to combine)

\item[\code{verbose}] print out informaiton

\item[\code{nb.top.features}] features to retain for visualization (top features with highest mean feature importance across datasets)

\item[\code{makeplot}] make a pdf file with the resulting plots (default:TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Combined visualization of feature prevalence in FBM + feature importance + feature effect size across groups + feature prevalence across groups in different predomics prediction tasks
\end{Value}
\inputencoding{utf8}
\HeaderA{plotModel}{Plots a model or a population of model objectsas barplots of scaled coefficients.}{plotModel}
%
\begin{Description}
Plots a model or a population of models as a barplots, representing each feature, the length being the coefficient
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotModel(
  mod,
  X,
  y,
  sort.features = FALSE,
  sort.ind = NULL,
  feature.name = FALSE,
  col.sign = c("deepskyblue1", "firebrick1"),
  main = "",
  slim = FALSE,
  importance = FALSE,
  res_clf = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to plot

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{sort.features:}] wether the features need to be sorted by correlation with 'y' or not (default: TRUE)

\item[\code{sort.ind:}] computing sorting can take time if computed for every model and can be computed outside the function and passed as a parameter

\item[\code{feature.name:}] show the name of the features (default:FALSE)

\item[\code{col.sign:}] the colors of the cofficients based on the sign of the coefficients (default: -1=deepskyblue1, 1:firebrick1)

\item[\code{main:}] possibility to change the title of the function (default:"")

\item[\code{slim:}] plot without axis information (default:FALSE)

\item[\code{importance:}] the importance (mda) of the features in crossval

\item[\code{res\_clf:}] the result of the learning process (default:NULL). If provided information on MDA will be extracted for the importance graphic.
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{plotModelScore}{Plots a model or a population of model objectsas barplots of scaled coefficients.}{plotModelScore}
%
\begin{Description}
Plots a model score or a population of models as a barplots, representing each feature, the length being the coefficient
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotModelScore(
  mod = NULL,
  y = NULL,
  col.sign = c("deepskyblue1", "firebrick1"),
  main = ""
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to plot

\item[\code{y:}] the class to predict

\item[\code{col.sign:}] the colors of the cofficients based on the sign of the coefficients (default: -1=deepskyblue1, 1:firebrick1)

\item[\code{main:}] possibility to change the title of the function (default:"")
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{plotPopulation}{Plots a population of models (or a single model) objects as barplots of scaled coefficients.}{plotPopulation}
%
\begin{Description}
Plots an model or a population of models as a barplots, representing each feature, the length being the coefficient
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotPopulation(
  pop,
  X,
  y,
  sort.features = FALSE,
  sort.ind = NULL,
  col.sign = c("deepskyblue1", "firebrick1"),
  ncol = 10,
  slim = FALSE,
  importance = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population of models to plot

\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the class vector

\item[\code{sort.features:}] wether the features need to be sorted by correlation with 'y' or not

\item[\code{sort.ind:}] computing sorting can take time if computed for every model and can be computed outside the function and passed as a parameter

\item[\code{col.sign:}] the colors of the cofficients based on the sign of the coefficients (default: -1=deepskyblue1,1:firebrick1)

\item[\code{ncol:}] number of graphics for each line (default: 10)

\item[\code{slim:}] plot without axis information (default:FALSE)

\item[\code{importance:}] the importance (mda) of the features in crossval
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{plotPrevalence}{Plots the prevalence of a list of features in the whole dataset and per each class}{plotPrevalence}
%
\begin{Description}
Plots the prevalence of a given number of features
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotPrevalence(
  features,
  X,
  y,
  topdown = TRUE,
  main = "",
  plot = TRUE,
  col.pt = c("deepskyblue4", "firebrick4"),
  col.bg = c("deepskyblue1", "firebrick1"),
  zero.value = 0
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{features:}] a list of features or features indexes for which we wish to compute prevalence

\item[\code{X:}] dataset where to compute the prevalence

\item[\code{y:}] if provided it will also compute hte prevalence per each class (default:NULL)

\item[\code{topdown:}] showing features from top-down or the other way around (default:TRUE)

\item[\code{main:}] main title (default:none)

\item[\code{plot:}] if TRUE this provides a plot, otherwise will return different metrics such as prevalence and enrichment statistics

\item[\code{col.pt:}] colors for the point border (-1:deepskyblue4, 1:firebrick4)

\item[\code{col.bg:}] colors for the point fill (-1:deepskyblue1, 1:firebrick1)

\item[\code{zero.value:}] the value that specifies what is zero. This can be a different than 0 in log transformed data for instance (default = 0)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a ggplot object
\end{Value}
\inputencoding{utf8}
\HeaderA{plotScoreBarcode}{Plots the barcode of the total score as well as positive and negative components}{plotScoreBarcode}
%
\begin{Description}
Plots the barcode of the total score as well as positive and negative components
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotScoreBarcode(dscore, y, nb.col.levels = 30, main = "")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dscore:}] an object containing different statistics on a model

\item[\code{y:}] the class vector

\item[\code{clf:}] an object containing the different parameters of the classifier

\item[\code{nb.col.levels:}] number of distinct colors from the viridis palette (default:30)

\item[\code{main:}] a title for the graphic
\end{ldescription}
\end{Arguments}
%
\begin{Value}
nothing
\end{Value}
\inputencoding{utf8}
\HeaderA{population}{Creates a population of index models.}{population}
%
\begin{Description}
This function is used in terga1 and generates a list of index vectors in the variable space. These vectors can be unique or not. NB that if clf\$params\$unique\_vars is set to TRUE it can take a long time to come out of the while loop which ensures the uniqueness of the individuals.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
population(
  clf,
  size_ind,
  size_world,
  best_ancestor = NULL,
  size_pop = NULL,
  seed = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier parameter object

\item[\code{size\_ind:}] The sparsity of the models. All the models of this population will have the same number of features.

\item[\code{size\_world:}] The number of features from which we can choose the indices. This is needed to compute the combinatory space search.

\item[\code{best\_ancestor:}] We can supply to the popolution an individual (vector with indeces) of a lower sparsity. This will ensure to seed part of the population with at least those genes. We added this feature after an observations that a local optimum of lower sparsity was lost in higher sparsities.

\item[\code{size\_pop:}] the number of models to produce (default=NULL). This information is stored here clf\$params\$size\_pop, but this parameter allows to override it.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a population of index models
\end{Value}
\inputencoding{utf8}
\HeaderA{populationGet\_X}{Get the best model from a classifier result}{populationGet.Rul.X}
%
\begin{Description}
Gets a given attribute from a population of predomics objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
populationGet_X(element2get, toVec = TRUE, na.rm = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{element2get:}] the name of the attribute to get

\item[\code{toVec:}] should the results be unlisted (default:TRUE)

\item[\code{na.rm:}] delete the elements that are NA (default) when returning tovec
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector of attributes
\end{Value}
\inputencoding{utf8}
\HeaderA{populationSet\_X}{Set models with a given liist of objects}{populationSet.Rul.X}
%
\begin{Description}
Sets a given attribute to the objects of the a given population
\end{Description}
%
\begin{Usage}
\begin{verbatim}
populationSet_X(pop, element2set = NULL, listwithelements = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{element2set:}] the name of the attribute to set

\item[\code{listwithelements:}] the list containing the elements to add
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an updated population
\end{Value}
\inputencoding{utf8}
\HeaderA{populationToDataFrame}{populationToDataFrame}{populationToDataFrame}
%
\begin{Description}
For each model in the list of models it will extract each attribute and create a dataframe needed for further exploration
\end{Description}
%
\begin{Usage}
\begin{verbatim}
populationToDataFrame(
  pop,
  attributes = c("learner", "language", "fit_", "unpenalized_fit_", "auc_", "accuracy_",
    "cor_", "aic_", "intercept_", "eval.sparsity", "sign_", "precision_", "recall_",
    "f1_")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a list of model objects, (i.e a population of models)

\item[\code{attributes:}] the list of attributes that we wish to have in the data.frame (default:"learner","language","fit\_", "unpenalized\_fit\_", "auc\_", "accuracy\_", "cor\_", "aic\_", "intercept\_", "eval.sparsity", "sign\_","precision\_", "recall\_","f1\_")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an data frame with attributes for each model
\end{Value}
\inputencoding{utf8}
\HeaderA{printClassifier}{Prints as text the detail on a given Classifier object}{printClassifier}
%
\begin{Description}
This function prints a summary of a Classifier object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printClassifier(obj, indent = "\t--- ")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a Classifier object

\item[\code{indent:}] a string (default:'tab---') that will precede each element of the object.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
NULL if the object is not a valid Classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{printExperiment}{Prints as text the detail on a given Experiment object}{printExperiment}
%
\begin{Description}
This function prints a summary of an Experiment object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printExperiment(obj, indent = "\t--- ")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an Experiment object

\item[\code{indent:}] a string (default:'tab---') that will precede each element of the object.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
NULL if the object is not a valid Experiment
\end{Value}
\inputencoding{utf8}
\HeaderA{printModel}{\# plot a horizontal barplot \#' @export plotBarplot <- function(v, rev=TRUE, xlim=range(v), main="") if(rev) v <- rev(v) barplot(v, las=2, horiz=TRUE, col="black", main=main, xlim=xlim) Prints a model object as text.}{printModel}
%
\begin{Description}
Prints a model object as text
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printModel(mod, method = "short", score = "fit_")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mod:}] a model to plot

\item[\code{method:}] an object containing the different parameters of the classifier

\item[\code{score:}] which score to show in the fit (default:fit\_)
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{printModelCollection}{Prints as text the detail on a given ModelCollection object}{printModelCollection}
%
\begin{Description}
This function prints a ModelCollection object. For each k\_sparsity it will show some detail of 
the maximum first models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printModelCollection(obj, indent = "\t--- ", method = "long")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a ModelCollection object

\item[\code{indent:}] a string (default:'tab---') that will precede each element of the object for the "long" method.

\item[\code{method:}] the output method (default:long) will print for each k\_sparsity a short information of the population of models, 
while the short method will output the number of models for each k\_sparsity
\end{ldescription}
\end{Arguments}
%
\begin{Value}
NULL if the object is not a valid ModelCollection.
\end{Value}
\inputencoding{utf8}
\HeaderA{printPopulation}{Prints a population of model objects as text.}{printPopulation}
%
\begin{Description}
Prints a population of model objects as text
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printPopulation(obj, method = "short", score = "fit_", indent = "")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] a population of models to plot

\item[\code{method:}] if "digested" a short sumary (one line) will be printed, otherwise the method will contain the 
specific way to print a model through the printModel() routine

\item[\code{score:}] which score to show in the fit (default:fit\_)

\item[\code{indent:}] a string (default:'tab---') that will precede each element of the object.
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{printy}{Prints as text the detail on a given object from the predomics package.}{printy}
%
\begin{Description}
This function will summarize any of the predomics package objects such as can be an Experiment, 
a Model, a Population of models or a ModelCollection
\end{Description}
%
\begin{Usage}
\begin{verbatim}
printy(obj)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] an object from the predomics object
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{resetTags}{Resets selection, mutation and mate tags to inactive}{resetTags}
%
\begin{Description}
Resets selection, mutation and mate tags to inactive
\end{Description}
%
\begin{Usage}
\begin{verbatim}
resetTags(pop, selected = FALSE, toBeMutated = FALSE, mate = -1)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] The population to be evolved

\item[\code{selected:}] set to (default:FALSE) the selected attribute, if not null.

\item[\code{toBeMutated:}] set to (default:FALSE) the selected attribute, if not null.

\item[\code{mate:}] set to (default:-1) the selected attribute, if not null.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A modified population
\end{Value}
\inputencoding{utf8}
\HeaderA{runClassifier}{Runs the learning on a dataset}{runClassifier}
%
\begin{Description}
This function runs a classifier in a given dataset
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runClassifier(X, y, clf, x_test = NULL, y_test = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] The dataset to classify

\item[\code{y:}] The variable to predict

\item[\code{clf:}] The classifier object containing the different settings of the classifier.

\item[\code{x\_test:}] if not NULL (default) this dataset will be used to evaluate the models in a subset for the feature importance

\item[\code{y\_test:}] if not NULL (default) this dataset will be used to evaluate the models in a subset for the feature importance
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the classifier along with the classification results as a sub-element
\end{Value}
\inputencoding{utf8}
\HeaderA{runCrossval}{Compute the cross-validation emprirical and generalization scores}{runCrossval}
%
\begin{Description}
Compute the cross-validation emprirical and generalization scores.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCrossval(X, y, clf, lfolds = NULL, nfolds = 10, return.all = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] the data matrix with variables in the rows and observations in the columns

\item[\code{y:}] the response vector

\item[\code{clf:}] the classifier parameter object

\item[\code{nfolds:}] the number of folds for the cross-validation

\item[\code{return.all:}] return all results from the crossvalidation for feature stability testing
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list containing empirical, generalisation scores for each fold as well as a matrix with the mean values.
\end{Value}
\inputencoding{utf8}
\HeaderA{savePopulation}{Save a population to a file}{savePopulation}
%
\begin{Description}
You can use this function to save a population to a file on you're disk (it will be in your working directory)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
savePopulation(pop, fileName, compress = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] The population to be saved

\item[\code{fileName:}] The name of the file were you want to save the population
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{saveResults}{Save the results of the fit function}{saveResults}
%
\begin{Description}
Save the results of the fit function
\end{Description}
%
\begin{Usage}
\begin{verbatim}
saveResults(fitResults, fileName, compress = TRUE)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{scoreRatio}{Computes the \textasciicircum{}y score of the model as a ratio}{scoreRatio}
%
\begin{Description}
Computes the \textasciicircum{}y score of the model as a ratio
\end{Description}
%
\begin{Usage}
\begin{verbatim}
scoreRatio(class_1_score, class_2_score, epsilon = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{class\_1\_score:}] the sum score for the features of class 1

\item[\code{class\_2\_score:}] the sum score for the features of class 2

\item[\code{epsilon:}] is a very small value that will would avoid Inf values in the ratio. This can be either specified in the when setting the classifier and if not specified will be set as the minimum number of the machine (e.g. 2.23e-308). Caution this should be adapted when working with other types of data.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a vector containing the predicted \textasciicircum{}y score for each observation
\end{Value}
\inputencoding{utf8}
\HeaderA{selectBestPopulation}{Select the top significant best part of the population}{selectBestPopulation}
%
\begin{Description}
This function allows to select the best part of a population that is significantly not different from the best model
\end{Description}
%
\begin{Usage}
\begin{verbatim}
selectBestPopulation(pop, score = "fit_", p = 0.05, k_penalty = 0, k_max = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a list of model objects

\item[\code{score:}] the attribute of the model to be used for the evaluation

\item[\code{p:}] the p-value threshold

\item[\code{k\_penalty:}] the penalty to apply to the score based on the k\_sparsity (default:0)

\item[\code{k\_max:}] select the best population below a given threshold. If (default:0) no selection is performed.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a sub part of the population
\end{Value}
\inputencoding{utf8}
\HeaderA{selector\_v1}{Does an elite selection on a population}{selector.Rul.v1}
%
\begin{Description}
This function is a template for other selectors, it takes a population and a number of individuals to select. The result is the \code{number} bests element of the population.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
selector_v1(pop, number, clf)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{sim\_inter}{compare stability of different modeles (inter k)}{sim.Rul.inter}
%
\begin{Description}
This function compares stability of different modeles (inter k)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sim_inter(tmp, X)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{tmp:}] the digested result from digest
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a num
\end{Value}
\inputencoding{utf8}
\HeaderA{sim\_intra}{compare stability of different modeles (intra k)}{sim.Rul.intra}
%
\begin{Description}
This function compares stability of different modeles (intra k)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sim_intra(tmp, X)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset to classify

\item[\code{tmp:}] the digested result from digest
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a num
\end{Value}
\inputencoding{utf8}
\HeaderA{sortPopulation}{sortPopulation}{sortPopulation}
%
\begin{Description}
Sort a population according to a given attribute (evalToOrder)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sortPopulation(pop, evalToOrder = "fit_", decreasing = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] a population (list) of evaluated predomics objects

\item[\code{evalToOrder:}] the attribute to be used in the sorting (default:fit\_)

\item[\code{decreasing:}] whether the sorting should be be decreasing or not (default:decreasing)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a sorted population of predomics objects
\end{Value}
\inputencoding{utf8}
\HeaderA{sota.glmnet}{sota.glmnet}{sota.glmnet}
%
\begin{Description}
sota.glmnet herits from terda and does not use the randomized rounding, using thus only the glmnet component
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sota.glmnet(...)
\end{verbatim}
\end{Usage}
%
\begin{Details}
sota.glmnet: sota.glmnet classifier parameter function
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{sota.rf}{sota.rf}{sota.rf}
%
\begin{Description}
sota.svm is a wrapper that executes svm using the same framework as for the predomics package.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sota.rf(
  sparsity = c(1:30),
  objective = "auc",
  max.nb.features = 1000,
  intercept = "NULL",
  language = "rf",
  evalToFit = "auc_",
  k_penalty = 0,
  ntree = 500,
  mtry = NULL,
  replace = TRUE,
  classwt = NULL,
  sampsize = NULL,
  nodesize = NULL,
  maxnodes = NULL,
  importance = FALSE,
  localImp = FALSE,
  nPerm = 1,
  norm.votes = TRUE,
  do.trace = FALSE,
  keep.forest = TRUE,
  corr.bias = FALSE,
  keep.inbag = FALSE,
  popSaveFile = "NULL",
  seed = "NULL",
  nCores = 4,
  verbose = TRUE,
  plot = FALSE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  experiment.id = NULL,
  experiment.description = NULL,
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"sota")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{objective:}] prediction mode (default: auc)

\item[\code{max.nb.features:}] create the glmnet object using only the top most significant features (default:1000)

\item[\code{intercept:}] (Interceot for the a given model) (default:NULL)

\item[\code{evalToFit:}] Which model property will be used to select the best model among different k\_sparsities (default: auc\_)

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{ntree:}] ??

\item[\code{mtry:}] Number of variables randomly sampled as candidates at each split. Note that the default values are different for classification (sqrt(p) where p is number of variables in x) and regression (p/3)

\item[\code{replace:}] Should sampling of cases be done with or without replacement?

\item[\code{classwt:}] Priors of the classes. Need not add up to one. Ignored for regression.

\item[\code{sampsize:}] Size(s) of sample to draw. For classification, if sampsize is a vector of the length the number of strata, then sampling is stratified by strata, and the elements of sampsize indicate the numbers to be drawn from the strata.

\item[\code{nodesize:}] Minimum size of terminal nodes. Setting this number larger causes smaller trees to be grown (and thus take less time). Note that the default values are different for classification (1) and regression (5).

\item[\code{maxnodes:}] Maximum number of terminal nodes trees in the forest can have. If not given, trees are grown to the maximum possible (subject to limits by nodesize). If set larger than maximum possible, a warning is issued.

\item[\code{importance:}] ??

\item[\code{localImp:}] ??

\item[\code{nPerm:}] ??

\item[\code{norm.votes:}] (??)

\item[\code{do.trace:}] ??

\item[\code{keep.forest:}] ??

\item[\code{cor.bias:}] ??

\item[\code{keep.inbag:}] ??

\item[\code{popSaveFile:}] (??)

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{nCores:}] the number of CPUs to run the programm in parallel

\item[\code{plot:}] Plot graphics indicating the evolution of the simulation (default:FALSE)

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print out information on the progress of the algorithm (default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"
\end{ldescription}
\end{Arguments}
%
\begin{Details}
sota.rf: launching Random Forest classifier
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{sota.svm}{sota.svm}{sota.svm}
%
\begin{Description}
sota.svm is a wrapper that executes svm using the same framework as for the predomics package.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sota.svm(
  sparsity = c(1:30),
  objective = "auc",
  max.nb.features = 1000,
  intercept = 0,
  language = "svm",
  evalToFit = "auc_",
  k_penalty = 0,
  scaled = TRUE,
  type = NULL,
  kernel = "rbfdot",
  kpar = "automatic",
  C = c(1e-04, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000),
  nu = 0.2,
  epsilon.hp = 0.1,
  prob.model = FALSE,
  class.weights = NULL,
  fit = TRUE,
  cache = 40,
  tol = 0.001,
  shrinking = TRUE,
  na.action = na.omit,
  popSaveFile = "NULL",
  seed = "NULL",
  nCores = 4,
  verbose = TRUE,
  plot = FALSE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  experiment.id = NULL,
  experiment.description = NULL,
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"sota")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{objective:}] prediction mode (default: auc)

\item[\code{max.nb.features:}] create the glmnet object using only the top most significant features (default:1000)

\item[\code{intercept:}] (Interceot for the a given model) (default:NULL)

\item[\code{evalToFit:}] Which model property will be used to select the best model among different k\_sparsities (default: auc\_)

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{scaled:}] ??

\item[\code{type:}] ??

\item[\code{kernel:}] ??

\item[\code{kpar:}] ??

\item[\code{C:}] (??)

\item[\code{nu:}] ??

\item[\code{epsilon.hp:}] (??) (for the SVM)

\item[\code{prob.model:}] ??

\item[\code{class.weights:}] ??

\item[\code{fit:}] ??

\item[\code{cache:}] (??)

\item[\code{tol:}] ??

\item[\code{shrinking:}] ??

\item[\code{na.action:}] ??

\item[\code{popSaveFile:}] (??)

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{nCores:}] the number of CPUs to run the program in parallel

\item[\code{plot:}] Plot graphics indicating the evolution of the simulation (default:FALSE)

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print out information on the progress of the algorithm (default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"
\end{ldescription}
\end{Arguments}
%
\begin{Details}
sota.svm: launching svm classifier
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{sparseVecToModel}{sparseVecToModel}{sparseVecToModel}
%
\begin{Description}
Builds a model object based on model that is in the sparse (short) format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sparseVecToModel(X, y, v, clf, eval.all = FALSE, obj = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] dataset

\item[\code{y:}] labels

\item[\code{v:}] A vector of indexes (example v=c(1,11))

\item[\code{clf:}] classifier information

\item[\code{eval.all:}] Should the model be evaluated (default:FALSE)

\item[\code{obj:}] an object model to add to the model (default:NULL)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an model object
\end{Value}
\inputencoding{utf8}
\HeaderA{summarySE}{Plot performance scores for multiple learners.}{summarySE}
%
\begin{Description}
summarySE gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95\%).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
summarySE(
  data = NULL,
  measurevar,
  groupvars = NULL,
  na.rm = FALSE,
  conf.interval = 0.95,
  .drop = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data:}] a data frame

\item[\code{groupvars:}] a vector containing names of columns that contain grouping variables

\item[\code{na.rm:}] a boolean that indicates whether to ignore NA's

\item[\code{conf.interval:}] the percent range of the confidence interval (default is 95\%)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A transformed data frame with information on the different errors and confidence.
\end{Value}
\inputencoding{utf8}
\HeaderA{t2d}{Type 2 diabetes (frequencies) BGI}{t2d}
\keyword{2}{t2d}
\keyword{diabetes,}{t2d}
\keyword{microbiome,}{t2d}
\keyword{species}{t2d}
\keyword{type}{t2d}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/
This is a list containing two elements: (i) the X data matrix with 1045 species and 344 observations and (ii) patient class = -1 (n=170) and healthy controls (n=174)
\end{Description}
%
\begin{Author}
Qin, Junjie, Yingrui Li, Zhiming Cai, Shenghui Li, Jianfeng Zhu, Fan Zhang, Suisha Liang, et al “A metagenome-wide association study of gut microbiota in type 2 diabetes.” Nature (September 26, 2012).
\end{Author}
\inputencoding{utf8}
\HeaderA{t2dw}{Type 2 diabetes (frequencies) Women Sweden}{t2dw}
\keyword{2}{t2dw}
\keyword{diabetes,}{t2dw}
\keyword{microbiome,}{t2dw}
\keyword{species}{t2dw}
\keyword{type}{t2dw}
%
\begin{Description}
This dataset consists of frequency abundance files as downloaded from http://waldronlab.io/curatedMetagenomicData/
This is a list containing two elements: (i) the X data matrix with 1045 species and 145 observations and (ii) patient class = -1 (n=53) and healthy controls (n=43)
Caution, this dataset has also a class 0 with IG patients, which needs to be omited from both X and y
\end{Description}
%
\begin{Author}
Karlsson, Fredrik H, Valentina Tremaroli, Intawat Nookaew, Göran Bergström, Carl Johan Behre, Björn Fagerberg, Jens Nielsen, and Fredrik Bäckhed. “Gut metagenome in European women with normal, impaired and diabetic glucose control.” Nature (May 29, 2013): 1–7.
\end{Author}
\inputencoding{utf8}
\HeaderA{tag\_Couples}{Tag the couples}{tag.Rul.Couples}
%
\begin{Description}
This function selects constitutes the couples that will give the
next generation individuals by adding the couple id on the mate attribute.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tag_Couples(pop, parents)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] The population on which we the couples are being constituted;

\item[\code{parents:}] The parent candidate individuals from which the couples will 
be selected.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The parent population with the couple tags set.
\end{Value}
\inputencoding{utf8}
\HeaderA{tag\_select}{Add `selected` tag using elite and random selection}{tag.Rul.select}
%
\begin{Description}
This function combines \LinkA{tag\_SelectElite}{tag.Rul.SelectElite} and \LinkA{tag\_SelectRandom}{tag.Rul.SelectRandom}
to tag the desired individuals in a population following the proportion given in the clf
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tag_select(X, y, clf, pop)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X:}] Unused but still here for compatibility

\item[\code{y:}] same as `X`

\item[\code{clf:}] the classifier object where parameters are defined

\item[\code{pop:}] the population on which we want to apply the selection
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the population with the tag `selected` on some of the individuals
\end{Value}
\inputencoding{utf8}
\HeaderA{tag\_SelectElite}{Tag individuals for parenting}{tag.Rul.SelectElite}
%
\begin{Description}
Function to add the tag "selected" to the best individuals of the population
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tag_SelectElite(clf, pop, nbToSelect)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] the classifier object

\item[\code{pop:}] the population on which we want to add the tag

\item[\code{nbToSelect:}] the number of individuals we are going to select in the population
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the population given as an input with `nbToSelect` bests individuals with `\$selected = TRUE`
\end{Value}
\inputencoding{utf8}
\HeaderA{tag\_SelectRandom}{Randomly tag selected individuals parenting}{tag.Rul.SelectRandom}
%
\begin{Description}
This function turns the selected switch on when an individual is 
selected to survive the generation and be among the pool of parents for the 
next generation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tag_SelectRandom(clf, pop, nbToSelect)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{clf:}] The classifier object

\item[\code{pop:}] The population on which the selection process will be performed.

\item[\code{nbToSelect:}] the number of individuals we are going to select in the population
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the population given as an input with `nbToSelect` individuals with `selected = TRUE`
\end{Value}
\inputencoding{utf8}
\HeaderA{tag\_ToBeMutated}{Tag individuals for mutation}{tag.Rul.ToBeMutated}
%
\begin{Description}
Function to add the tag "toBeMutated" to a randomly sampled part of 
the population. Some individuals (the best ones) will be protected from the mutation
so that genetic decline does not happen.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tag_ToBeMutated(pop, mutate_size, protected = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pop:}] The population on which the individuals to be mutated will be selected

\item[\code{mutate\_size:}] The number of individuals to mutate

\item[\code{protected:}] The index of individuals which should not be mutated.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The population given as an input with `mutate\_size` individuals with `toBeMutated = TRUE`
\end{Value}
\inputencoding{utf8}
\HeaderA{terBeam}{terbeam}{terBeam}
%
\begin{Description}
terbeam is a model search algorithm on a beam search approach.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
terBeam(
  sparsity = 1:5,
  max.nb.features = 1000,
  maxNbOfModels = 10000,
  nbBest = round(maxNbOfModels/10),
  nbVeryBest = round(maxNbOfModels/100),
  final.pop.perc = 100,
  popSaveFile = "NULL",
  saveFiles = FALSE,
  language = "terinter",
  scoreFormula = scoreRatio,
  epsilon = "NULL",
  objective = "auc",
  k_penalty = 0,
  evalToFit = "auc_",
  estimate_coefs = FALSE,
  intercept = "NULL",
  testAllSigns = FALSE,
  plot = FALSE,
  verbose = TRUE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  parallelize.folds = TRUE,
  nCores = 4,
  seed = "NULL",
  experiment.id = "NULL",
  experiment.description = "NULL",
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"terinter")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{maxNbOfModels:}] number of models to be explored for a given k\_sparsity. This is equivalent to a population size in terga.

\item[\code{nbVeryBest:}] is the number of features to be kept that appear in the very best models. They will be kept even if they are not frequent in the best models (default: 1 percent of maxNbOfModels).

\item[\code{nbBest:}] is the number of features that will be used to build the k+1 sparsity combinations (default: 10 percent of maxNbOfModels).

\item[\code{final.pop.perc:}] a percentage of nbVeryBest translates in a number of models to be kept for k\_sparsity.

\item[\code{popSaveFile:}] (??)

\item[\code{saveFiles:}] ??

\item[\code{scoreFormula:}] a Function that contains the ratio Formula or other specific ones

\item[\code{epsilon:}] a small value to be used with the ratio language (useCustomLanguage) (default: NULL). When null it is going to be calculated by the minimum value of X divided by 10.

\item[\code{objective:}] this can be auc, cor or aic. Terga can also predict regression, other than class prediction. (default:auc)

\item[\code{max.nb.features:}] focuses only on the subset of top most significant features (default:1000)

\item[\code{estimate\_coefs:}] non ternary solution for the aic objective (default:FALSE)

\item[\code{evalToFit:}] The model performance attribute to use as fitting score (default:"fit\_"). Other choices are c("auc\_","accuracy\_","precision\_","recall\_","f\_score\_")

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{intercept:}] (??) (default:NULL)

\item[\code{testAllSigns:}] ??

\item[\code{plot:}] Plot different graphics (default:FALSE).

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print debug information (default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{nCores:}] the number of cores to execute the program. If nCores=1 than the program runs in a non parallel mode

\item[\code{parallelize.folds:}] parallelize folds when cross-validating (default:TRUE)

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"

\item[\code{parallel:}] parallel
\end{ldescription}
\end{Arguments}
%
\begin{Details}
terbeam: ternary beam searching algorithm
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{terda}{terda}{terda}
%
\begin{Description}
terbeam is a model search algorithm.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
terda(
  sparsity = 5,
  nIterations = 5,
  max.nb.features = 1000,
  kBest = "NULL",
  method = "glmnetRR",
  kStep = "NULL",
  vartype = "real",
  gamma = 0.7,
  nRR = 1,
  lb = -1,
  ub = 1,
  language = "terinter",
  scoreFormula = scoreRatio,
  epsilon = "NULL",
  nblambdas = 1000,
  objective = "auc",
  evalToFit = "auc_",
  k_penalty = 0,
  intercept = "NULL",
  popSaveFile = "NULL",
  final.pop.perc = 100,
  alpha = 0.5,
  plot = FALSE,
  verbose = TRUE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  parallelize.folds = TRUE,
  nCores = 4,
  seed = "NULL",
  experiment.id = "NULL",
  experiment.description = "NULL",
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"terinter")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{nIterations:}] ??

\item[\code{max.nb.features:}] create the glmnet object using only the top most significant features (default:1000)

\item[\code{kBest:}] ??

\item[\code{method:}] ??

\item[\code{kStep:}] ??

\item[\code{vartype:}] (??)

\item[\code{gamma:}] ??

\item[\code{nRR:}] (??) (default:FALSE)

\item[\code{lb:}] ??

\item[\code{ub:}] ??

\item[\code{scoreFormula:}] a Function that contains the ratio Formula or other specific ones

\item[\code{epsilon:}] a small value to be used with the ratio language (useCustomLanguage) (default: NULL). When null it is going to be calculated by the minimum value of X divided by 10.

\item[\code{objective:}] this can be auc, cor or aic. Terga can also predict regression, other than class prediction. (default:auc)

\item[\code{evalToFit:}] The model performance attribute to use as fitting score (default:"fit\_"). Other choices are c("auc\_","accuracy\_","precision\_","recall\_","f\_score\_")

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{intercept:}] (??) (default:NULL)

\item[\code{popSaveFile:}] (??)

\item[\code{final.pop.perc:}] ??

\item[\code{plot:}] Plot different graphics (default:FALSE).

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print out debug infotmation when activated (default: FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{parallelize.folds:}] parallelize folds when cross-validating (default:TRUE)

\item[\code{nCores:}] the number of cores to execute the program. If nCores=1 than the program runs in a non parallel mode

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"
\end{ldescription}
\end{Arguments}
%
\begin{Details}
terda: terda classifier parameter function
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{terga1}{terga1}{terga1}
%
\begin{Description}
terga1 is a model search algorithm based on genetic algorithms (GA). A “genome” or “individual” in this context is a combination of features that will be associated together to compute a score that will be the prediction model. Depending on the type of fitting function that is maximized the fatures are weighed by specific coefficients. In short the algorithm is based on different operations such as crossing, mutating and evolving different “individuals” and evaluating their fitness to the “environment” which is represented by the variable to be predicted.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
terga1(
  sparsity = c(1:10),
  size_pop = 100,
  size_world = "NULL",
  max.nb.features = 1000,
  popSourceFile = "NULL",
  popSaveFile = "NULL",
  language = "terinter",
  scoreFormula = scoreRatio,
  epsilon = "NULL",
  unique_vars = FALSE,
  objective = "auc",
  k_penalty = 0,
  evalToFit = "fit_",
  estimate_coefs = FALSE,
  intercept = "NULL",
  select_type = "mixed",
  select_perc1 = 20,
  select_perc2 = 30,
  perc_best_ancestor = 10,
  mutate_size = 70,
  mutate_rate = 50,
  nb_generations = 100,
  convergence = TRUE,
  convergence_steps = 10,
  evolve_k1 = TRUE,
  plot = FALSE,
  verbose = TRUE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  parallelize.folds = TRUE,
  nCores = 4,
  seed = "NULL",
  experiment.id = "NULL",
  experiment.description = "NULL",
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms bin, bininter, ter, terinter, ratio, (default:"terinter")

\item[\code{sparsity:}] number of features in a given model. This is a vector with multiple lengths.

\item[\code{size\_pop:}] the number of individuals in a population to be evolved.

\item[\code{size\_world:}] this is the number of features in the dataset.

\item[\code{max.nb.features:}] focuses only on the subset of top most significant features (default:1000)

\item[\code{popSourceFile:}] A population of models that can start as a first generation to be evolved (default:NULL).

\item[\code{popSaveFile:}] (??)

\item[\code{scoreFormula:}] a Function that contains the ratio Formula or other specific ones

\item[\code{epsilon:}] a small value to be used with the ratio language (default: NULL). When null it is going to be calculated by the minimum value of X divided by 10.

\item[\code{unique\_vars:}] logical (default: FALSE) indicates weather unique variables can be used in a model or population.

\item[\code{objective:}] this can be auc, cor or aic. Terga can also predict regression, other than class prediction. (default:auc)

\item[\code{estimate\_coefs:}] non ternary solution for the aic objective (default:FALSE)

\item[\code{intercept:}] (Interceot for the a given model) (default:NULL)

\item[\code{evalToFit:}] The model performance attribute to use as fitting score (default:"fit\_"). Other choices are c("auc\_","accuracy\_","precision\_","recall\_","f\_score\_")

\item[\code{k\_penalty:}] Penalization of the fit by the k\_sparsity (default: 0)

\item[\code{select\_type:}] the selection operator type. can be mixed, elite or tournoi (default: mixed)

\item[\code{select\_perc1:}] percentage of individuals to be selected with elite

\item[\code{select\_perc2:}] percentage of individuals to be selected with tournoi

\item[\code{perc\_best\_ancestor:}] percentage of best ancentors as seeding in the new population

\item[\code{mutate\_size:}] percentage of individuals in the population to be mutated

\item[\code{mutate\_rate:}] percentage of features in an individual to be mutated

\item[\code{plot:}] plot graphics indicating the evolution of the simulation (default:FALSE)

\item[\code{convergence:}] should the algorithm converge when the best individual is not improving (default:TRUE).

\item[\code{convergence\_steps:}] the number of generations after which we consider convergence (default:10).

\item[\code{evolve\_k1:}] weather or not to evaluate exhaustively the features for k\_sparse=1. This will take a lot of time if the dataset is large, thus the possibility to evolve this using the GA. (default:TRUE)

\item[\code{verbose:}] print out information on the progress of the algorithm (default:TRUE)

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] print debug information (default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print a model and subsequently a population during the run (default:"short").

\item[\code{parallelize.folds:}] parallelize folds when cross-validating (default:TRUE)

\item[\code{nb\_generations:}] maximum number of generations to evolve the population.

\item[\code{nCores:}] the number of cores to execute the program. If nCores=1 than the program runs in a non parallel mode

\item[\code{seed:}] the seed to be used for reproductibility. If seed=NULL than it is not taken into account (default:NULL).

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is important when many experiments are run and can also be printed in by the printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different levels of completness, with options to be selected from c("nothing", "minimal", "full"), default is "minimal"
\end{ldescription}
\end{Arguments}
%
\begin{Details}
terga1: Model search algorithm based on genetic algorithms (GA)
\end{Details}
%
\begin{Value}
an object containing a list of parameters for this classifier
\end{Value}
\inputencoding{utf8}
\HeaderA{terga2}{Model search algorithm based on genetic algorithms (GA).}{terga2}
%
\begin{Description}
TerGA is a model search algorithm based on genetic algorithms (GA). 
An “individual” (i.e. genome) in this context is a combination of features that 
will be associated together using a selected "language" to compute a score that 
will constitute the prediction model. Depending on the type of fitting (i.e. evaluation)
function that is maximized, the fatures are weighed by specific coefficients. 
In short the algorithm is based on different operations such as crossing, mutating 
and evolving different “individuals” and evaluating their fitness to the “environment” 
which is represented by the variable to be predicted.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
terga2(
  sparsity = c(1:10),
  max.nb.features = 1000,
  language = "terinter",
  objective = "auc",
  evalToFit = "accuracy_",
  k_penalty = 0,
  estimate_coefs = FALSE,
  scoreFormula = scoreRatio,
  epsilon = "NULL",
  size_pop = 100,
  size_pop_random = size_pop,
  final.pop.perc = 100,
  in_pop = "NULL",
  popSourceFile = "NULL",
  popSaveFile = "NULL",
  individual_vec = individual_vec_v2,
  randomSigns = FALSE,
  unique_vars = FALSE,
  select_perc = 25,
  selector = list(selector_v1, selector_v2),
  select_percByMethod = list(50, 50),
  cross = TRUE,
  crosser = crossingIndividual_v3,
  mutate = TRUE,
  mutate_size = 75,
  mutate_rate = 50,
  mutator = mutator_v2,
  evolver = "v2m",
  nb_generations = 100,
  convergence = TRUE,
  convergence_steps = 10,
  evolve_k1 = TRUE,
  plot = FALSE,
  verbose = FALSE,
  warnings = FALSE,
  debug = FALSE,
  print_ind_method = "short",
  parallelize.folds = TRUE,
  nCores = 4,
  seed = "NULL",
  maxTime = Inf,
  experiment.id = "NULL",
  experiment.description = "NULL",
  experiment.save = "nothing"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{language}] is the language that is used by the different algorithms 
bin, bininter, ter, terinter, (default:"terinter")

\item[\code{size\_pop\_random}] the number of individuals initialized randomly. This is used 
by the metal algorithm (i.e. aggregator method).

\item[\code{sparsity:}] number of features in a given model (default:1:10). 
This is a vector with the model-size range (number of features used by a model).

\item[\code{objective:}] This is the task that is to be learned and can be either classification 
(auc) or can be a regression (cor) (default:auc).

\item[\code{evalToFit:}] The model performance attribute to use as fitting score (default:"accuracy\_"). 
Other choices are c("accuracy\_", "auc\_", "precision\_","recall\_","f\_score\_") for the 
classification task. It can be either rho, rho-squared or minimizing the 
standar error of the regression for the regression task.

\item[\code{k\_penalty:}] Model-size penalization effect applied on the fit scpre (default: 0).

\item[\code{estimate\_coefs:}] \_deprecated\_ A particular option for the regression mode
with the aic objective (default:FALSE)

\item[\code{max.nb.features:}] If this number is smaller than the number of variables in the
dataset, the max.nb.features most significant features will be selected and the 
dataset will be restricted (default:1000).

\item[\code{size\_pop:}] the number of individuals in a population to be evolved (default:100)

\item[\code{final.pop.perc:}] What percentage of the final population should be returned (default:100)

\item[\code{in\_pop:}] a specific population of models that can be evolved. This is particulary
useful for the metal algorithm

\item[\code{popSourceFile:}] It is possible to load a population of models that has been
already learned before. With this option we can specify such file (default:NULL).

\item[\code{popSaveFile:}] Once the population of models evolved, we can store it in 
another file (default:NULL).

\item[\code{scoreFormula:}] a Function that contains the ratio Formula or other specific ones

\item[\code{epsilon:}] a very small value to be used with the ratio language 
(useCustomLanguage) (default: NULL). When null it is going to be calculated by the 
minimum value of X divided by 10.

\item[\code{individual\_vec:}] The function that is used to generate an individual 
(default:individual\_vec\_v2).

\item[\code{randomSigns:}] When generating an individual composed of a set of features, we 
can set the coefficients of the variables from -1 or 1 randomly (default:FALSE).

\item[\code{unique\_vars:}] When performing operations on multiple individuals it can be 
that in an individual we have multiple time the same feature. If set to TRUE this 
individual will be destroyed (default:FALSE)

\item[\code{select\_perc:}] The percentage of the population to be selected for crossing/mutation 
(default:50)

\item[\code{selector:}] During the selection process, the parent population can be
selected using different strategies. For instance the default process is performed
using both elite and random selection (default:list(selector\_v1, selector\_v2)).

\item[\code{select\_percByMethod:}] A list contaning the percentage of individuals that
each of the methods specified in selector should get.

\item[\code{cross:}] A swithch, which activates the crossing operator (default:TRUE).

\item[\code{crosser:}] The method that should be applied to cross individuals
together (default:crossingIndividual\_v4).

\item[\code{mutate:}] A swithch, which activates the mutation operator (default:TRUE).

\item[\code{mutate\_size:}] The percentage of individuals in the population to be mutated (default:70).

\item[\code{mutate\_rate:}] The percentage of features in an individual to be mutated (default:50).

\item[\code{mutator:}] The method that should be applied to mutate individuals (default:mutator\_v2).
The operations can be, deletion, insertion or changing the coeffiecient (from -1 to 1
and vice-versa).

\item[\code{evolver:}] The method that will be used to evolve the individuals together.
This is the core of the algorithm and can be one of different implementations 
c("v1", "v2", "v3","v4") where the default one is "v4".

\item[\code{nb\_generations:}] The maximum number of generations to evolve the population.

\item[\code{convergence:}] A switch which activates the automatic convergence of the algorithm
when the best individual is not improving (default:TRUE).

\item[\code{convergence\_steps:}] The number of generations after which we consider 
convergence (default:10).

\item[\code{evolve\_k1:}] Whether or not to evaluate exhaustively the features for 
model size = 1. This will take a lot of time if the dataset is large, thus the
possibility to evolve this using the GA is interesting. (default:TRUE)

\item[\code{plot:}] Plot graphics indicating the evolution of the simulation (default:FALSE)

\item[\code{verbose:}] Print out information on the progress of the algorithm (default:FALSE).

\item[\code{warnings:}] Print out warnings when runnig (default:FALSE).

\item[\code{debug:}] Print out detailed information on the progress of the algorithm 
(default:FALSE)

\item[\code{print\_ind\_method:}] One of c("short","graphical") indicates how to print 
a model and subsequently a population during the run (default:"short").

\item[\code{parallelize.folds:}] parallelize folds when cross-validating (default:TRUE).

\item[\code{nCores:}] The number of cores to execute the program. If nCores = 1 than 
the program runs in a non parallel mode

\item[\code{seed:}] The seed to be used for reproductibility. If seed=NULL than it is 
not taken into account (default:NULL).

\item[\code{maxTime:}] We can use a time limit to evolve a population (default:Inf).

\item[\code{experiment.id:}] The id of the experiment that is to be used in the plots 
and comparitive analyses (default is the learner's name, when not specified)

\item[\code{experiment.description:}] A longer description of the experiment. This is 
important when many experiments are run and can also be printed in by the 
printExperiment function.

\item[\code{experiment.save:}] Data from an experiment can be saved with different 
levels of completness, with options to be selected from 
c("nothing", "minimal", "full"), default is "minimal"
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object of the classifier class, containing a list of parameters
\end{Value}
\inputencoding{utf8}
\HeaderA{updateModelIndex}{updateModelIndex}{updateModelIndex}
%
\begin{Description}
Update the index of a model objectn.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
updateModelIndex(obj, features = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] the object is a model

\item[\code{features:}] the list of features which overrides the clf\$data\$features if this exists.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
the same object type as input, but updated
\end{Value}
\inputencoding{utf8}
\HeaderA{updateObjectIndex}{updateObjectIndex}{updateObjectIndex}
%
\begin{Description}
Update the index of a model, population, or modelCollection.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
updateObjectIndex(obj, features = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj:}] the object can be a model, population, or modelCollection

\item[\code{features:}] the list of features which overrides the clf\$data\$features if this exists.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an the same object type as input, but updated
\end{Value}
\printindex{}
\end{document}
